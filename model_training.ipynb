{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Using TensorFlow Version:  2.8.0\n",
      "• Using TensorFlow Version:  0.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import RandomFourierFeatures\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflowjs as tfjs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('\\u2022 Using TensorFlow Version: ', tf.__version__)\n",
    "print('\\u2022 Using TensorFlow Version: ', tfa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders & Paths\n",
    "audio_path = './audio/'\n",
    "\n",
    "features_path = './features/Normalized_Features.csv'\n",
    "\n",
    "truth_path = './truth/ratings/'\n",
    "aro_truth_path = truth_path + 'Arousal.csv'\n",
    "val_truth_path = truth_path + 'Valence.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = pd.read_csv(features_path)\n",
    "aro_truth = pd.read_csv(aro_truth_path, header=None)\n",
    "val_truth = pd.read_csv(val_truth_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>decreaseslope_mean</th>\n",
       "      <th>fluctuation_max</th>\n",
       "      <th>eventdensity_mean</th>\n",
       "      <th>zerocross_mean</th>\n",
       "      <th>zerocross_std</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_std</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>perceptual_sharp_mean</th>\n",
       "      <th>perceptual_sharp_std</th>\n",
       "      <th>spectral_slope_mean</th>\n",
       "      <th>spectral_slope_std</th>\n",
       "      <th>spectral_var_mean</th>\n",
       "      <th>spectral_var_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_between_human_indicator_1-12_1-6.wav</td>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>0.206975</td>\n",
       "      <td>0.078080</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.176589</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.496309</td>\n",
       "      <td>0.199965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-12.wav</td>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.196134</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139904</td>\n",
       "      <td>0.240593</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508387</td>\n",
       "      <td>0.214740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-6.wav</td>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>0.206228</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.058544</td>\n",
       "      <td>0.180633</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.116314</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.500550</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_between_human_indicator_2-12_2-6.wav</td>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.261880</td>\n",
       "      <td>0.083218</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.160497</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.114858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.539779</td>\n",
       "      <td>0.173066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_between_human_indicator_2-6_2-12.wav</td>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.076265</td>\n",
       "      <td>0.260347</td>\n",
       "      <td>0.087722</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.278942</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.277877</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.076973</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.540959</td>\n",
       "      <td>0.129461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>r_5indicator59071_8556-hq.wav</td>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.107604</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>0.163258</td>\n",
       "      <td>0.296059</td>\n",
       "      <td>0.119320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>r_6mechanical60455_27178-hq.wav</td>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.286410</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>0.311533</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.245375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.453177</td>\n",
       "      <td>0.157346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r_6mechanical66618_800302-hq.wav</td>\n",
       "      <td>0.339912</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.557340</td>\n",
       "      <td>0.047963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.187232</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>0.190987</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.402072</td>\n",
       "      <td>0.188584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>r_7mechanical54899_170972-hq.wav</td>\n",
       "      <td>0.136810</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.175816</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378655</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>0.136725</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.192803</td>\n",
       "      <td>0.371038</td>\n",
       "      <td>0.110928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>r_8indicator262210_4415905-hq.wav</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>0.968749</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.182074</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.194318</td>\n",
       "      <td>0.401578</td>\n",
       "      <td>0.229771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fileName  rms_mean   rms_std  \\\n",
       "0     mix_between_human_indicator_1-12_1-6.wav  0.057916  0.181649   \n",
       "1     mix_between_human_indicator_1-6_1-12.wav  0.029380  0.090423   \n",
       "2      mix_between_human_indicator_1-6_1-6.wav  0.058108  0.181268   \n",
       "3     mix_between_human_indicator_2-12_2-6.wav  0.034239  0.044759   \n",
       "4     mix_between_human_indicator_2-6_2-12.wav  0.064380  0.076265   \n",
       "...                                        ...       ...       ...   \n",
       "1208             r_5indicator59071_8556-hq.wav  0.106141  0.046720   \n",
       "1209           r_6mechanical60455_27178-hq.wav  0.077711  0.046950   \n",
       "1210          r_6mechanical66618_800302-hq.wav  0.339912  0.174158   \n",
       "1211          r_7mechanical54899_170972-hq.wav  0.136810  0.058775   \n",
       "1212         r_8indicator262210_4415905-hq.wav  0.090646  0.079490   \n",
       "\n",
       "      decreaseslope_mean  fluctuation_max  eventdensity_mean  zerocross_mean  \\\n",
       "0               0.206975         0.078080           0.180149        0.080720   \n",
       "1               0.196134         0.070676           0.180149        0.078890   \n",
       "2               0.206228         0.076273           0.180149        0.079321   \n",
       "3               0.261880         0.083218           0.340900        0.160497   \n",
       "4               0.260347         0.087722           0.843000        0.168180   \n",
       "...                  ...              ...                ...             ...   \n",
       "1208            0.107604         0.043783           1.000000        0.206274   \n",
       "1209            0.123511         0.035052           1.000000        0.112818   \n",
       "1210            0.557340         0.047963           1.000000        0.045219   \n",
       "1211            0.110323         0.037463           1.000000        0.078109   \n",
       "1212            0.111319         0.037404           0.968749        0.045652   \n",
       "\n",
       "      zerocross_std  rolloff_mean  rolloff_std  ...  loudness_mean  \\\n",
       "0          0.321308      0.128489     0.121556  ...       0.191118   \n",
       "1          0.315966      0.156579     0.222034  ...       0.139904   \n",
       "2          0.308780      0.140393     0.199835  ...       0.193484   \n",
       "3          0.287264      0.292328     0.114858  ...       0.199732   \n",
       "4          0.278942      0.297361     0.113448  ...       0.272825   \n",
       "...             ...           ...          ...  ...            ...   \n",
       "1208       0.211808      0.564615     0.171320  ...       0.374871   \n",
       "1209       0.250360      0.286410     0.432750  ...       0.267722   \n",
       "1210       0.187232      0.152356     0.053483  ...       0.497385   \n",
       "1211       0.175816      0.172034     0.052256  ...       0.378655   \n",
       "1212       0.187891      0.106409     0.039075  ...       0.253873   \n",
       "\n",
       "      loudness_std  energy_mean  energy_std  perceptual_sharp_mean  \\\n",
       "0         0.347576     0.058354    0.181010               0.176589   \n",
       "1         0.240593     0.029598    0.090092               0.204845   \n",
       "2         0.344449     0.058544    0.180633               0.184976   \n",
       "3         0.199390     0.034204    0.045013               0.315799   \n",
       "4         0.277877     0.064285    0.076973               0.322426   \n",
       "...            ...          ...         ...                    ...   \n",
       "1208      0.258196     0.106127    0.048706               0.383245   \n",
       "1209      0.311533     0.077776    0.047545               0.245375   \n",
       "1210      0.659042     0.339674    0.181340               0.190987   \n",
       "1211      0.404539     0.136725    0.062171               0.202077   \n",
       "1212      0.368001     0.090647    0.080159               0.182074   \n",
       "\n",
       "      perceptual_sharp_std  spectral_slope_mean  spectral_slope_std  \\\n",
       "0                 0.352935             0.114804            0.356061   \n",
       "1                 0.335579             0.132931            0.344697   \n",
       "2                 0.337910             0.116314            0.344697   \n",
       "3                 0.262805             0.212991            0.295455   \n",
       "4                 0.252839             0.217523            0.291667   \n",
       "...                    ...                  ...                 ...   \n",
       "1208              0.122873             0.326284            0.163258   \n",
       "1209              0.201658             0.160121            0.242424   \n",
       "1210              0.162281             0.096677            0.193182   \n",
       "1211              0.161894             0.117825            0.192803   \n",
       "1212              0.165173             0.086103            0.194318   \n",
       "\n",
       "      spectral_var_mean  spectral_var_std  \n",
       "0              0.496309          0.199965  \n",
       "1              0.508387          0.214740  \n",
       "2              0.500550          0.196160  \n",
       "3              0.539779          0.173066  \n",
       "4              0.540959          0.129461  \n",
       "...                 ...               ...  \n",
       "1208           0.296059          0.119320  \n",
       "1209           0.453177          0.157346  \n",
       "1210           0.402072          0.188584  \n",
       "1211           0.371038          0.110928  \n",
       "1212           0.401578          0.229771  \n",
       "\n",
       "[1213 rows x 123 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized features statistics\n",
    "features_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_between_human_indicator_1-12_1-6.wav</td>\n",
       "      <td>0.523495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-12.wav</td>\n",
       "      <td>0.211871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-6.wav</td>\n",
       "      <td>0.589448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_between_human_indicator_2-12_2-6.wav</td>\n",
       "      <td>0.396538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_between_human_indicator_2-6_2-12.wav</td>\n",
       "      <td>0.764221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>r_5indicator59071_8556-hq.wav</td>\n",
       "      <td>0.902721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>r_6mechanical60455_27178-hq.wav</td>\n",
       "      <td>0.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r_6mechanical66618_800302-hq.wav</td>\n",
       "      <td>0.968673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>r_7mechanical54899_170972-hq.wav</td>\n",
       "      <td>0.812036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>r_8indicator262210_4415905-hq.wav</td>\n",
       "      <td>0.927453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0         1\n",
       "0     mix_between_human_indicator_1-12_1-6.wav  0.523495\n",
       "1     mix_between_human_indicator_1-6_1-12.wav  0.211871\n",
       "2      mix_between_human_indicator_1-6_1-6.wav  0.589448\n",
       "3     mix_between_human_indicator_2-12_2-6.wav  0.396538\n",
       "4     mix_between_human_indicator_2-6_2-12.wav  0.764221\n",
       "...                                        ...       ...\n",
       "1208             r_5indicator59071_8556-hq.wav  0.902721\n",
       "1209           r_6mechanical60455_27178-hq.wav  0.655400\n",
       "1210          r_6mechanical66618_800302-hq.wav  0.968673\n",
       "1211          r_7mechanical54899_170972-hq.wav  0.812036\n",
       "1212         r_8indicator262210_4415905-hq.wav  0.927453\n",
       "\n",
       "[1213 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arousal ground truth ratings\n",
    "aro_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.523495\n",
       "1       0.211871\n",
       "2       0.589448\n",
       "3       0.396538\n",
       "4       0.764221\n",
       "          ...   \n",
       "1208    0.902721\n",
       "1209    0.655400\n",
       "1210    0.968673\n",
       "1211    0.812036\n",
       "1212    0.927453\n",
       "Name: 1, Length: 1213, dtype: float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aro_y = aro_truth[1].astype(np.float32)\n",
    "aro_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_between_human_indicator_1-12_1-6.wav</td>\n",
       "      <td>-0.767519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-12.wav</td>\n",
       "      <td>-0.577906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-6.wav</td>\n",
       "      <td>-0.752679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_between_human_indicator_2-12_2-6.wav</td>\n",
       "      <td>0.526793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_between_human_indicator_2-6_2-12.wav</td>\n",
       "      <td>-0.190437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>r_5indicator59071_8556-hq.wav</td>\n",
       "      <td>-0.952185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>r_6mechanical60455_27178-hq.wav</td>\n",
       "      <td>-0.742786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r_6mechanical66618_800302-hq.wav</td>\n",
       "      <td>-0.965375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>r_7mechanical54899_170972-hq.wav</td>\n",
       "      <td>0.022259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>r_8indicator262210_4415905-hq.wav</td>\n",
       "      <td>-0.592745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0         1\n",
       "0     mix_between_human_indicator_1-12_1-6.wav -0.767519\n",
       "1     mix_between_human_indicator_1-6_1-12.wav -0.577906\n",
       "2      mix_between_human_indicator_1-6_1-6.wav -0.752679\n",
       "3     mix_between_human_indicator_2-12_2-6.wav  0.526793\n",
       "4     mix_between_human_indicator_2-6_2-12.wav -0.190437\n",
       "...                                        ...       ...\n",
       "1208             r_5indicator59071_8556-hq.wav -0.952185\n",
       "1209           r_6mechanical60455_27178-hq.wav -0.742786\n",
       "1210          r_6mechanical66618_800302-hq.wav -0.965375\n",
       "1211          r_7mechanical54899_170972-hq.wav  0.022259\n",
       "1212         r_8indicator262210_4415905-hq.wav -0.592745\n",
       "\n",
       "[1213 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valence ground truth ratings\n",
    "val_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.767519\n",
       "1      -0.577906\n",
       "2      -0.752679\n",
       "3       0.526793\n",
       "4      -0.190437\n",
       "          ...   \n",
       "1208   -0.952185\n",
       "1209   -0.742786\n",
       "1210   -0.965375\n",
       "1211    0.022259\n",
       "1212   -0.592745\n",
       "Name: 1, Length: 1213, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val_truth[1].astype(np.float32)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1213\n"
     ]
    }
   ],
   "source": [
    "files_list = features_norm['fileName'].tolist()\n",
    "print(f'Number of files: {len(files_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 14\n"
     ]
    }
   ],
   "source": [
    "# Meyda extractable features\n",
    "features = ['rms','zerocross','rolloff','centroid','spread','skewness','kurtosis','flatness','mfcc','chromagram','loudness','energy','perceptual_sharp','spectral_slope']\n",
    "# meyda_available_features = ['rms','zcr','spectralRolloff','spectralCentroid','spectralSpread','spectralSkewness','spectralKurtosis','spectralFlatness','mfcc','chroma','loudness','energy','perceptualSharpness','spectralSlope']\n",
    "\n",
    "print(f'Number of features: {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rms_mean',\n",
       " 'rms_std',\n",
       " 'zerocross_mean',\n",
       " 'zerocross_std',\n",
       " 'rolloff_mean',\n",
       " 'rolloff_std',\n",
       " 'centroid_mean',\n",
       " 'centroid_std',\n",
       " 'spread_mean',\n",
       " 'spread_std',\n",
       " 'skewness_mean',\n",
       " 'skewness_std',\n",
       " 'kurtosis_mean',\n",
       " 'kurtosis_std',\n",
       " 'flatness_mean',\n",
       " 'flatness_std',\n",
       " 'mfcc_mean_1',\n",
       " 'mfcc_mean_2',\n",
       " 'mfcc_mean_3',\n",
       " 'mfcc_mean_4',\n",
       " 'mfcc_mean_5',\n",
       " 'mfcc_mean_6',\n",
       " 'mfcc_mean_7',\n",
       " 'mfcc_mean_8',\n",
       " 'mfcc_mean_9',\n",
       " 'mfcc_mean_10',\n",
       " 'mfcc_mean_11',\n",
       " 'mfcc_mean_12',\n",
       " 'mfcc_mean_13',\n",
       " 'mfcc_std_1',\n",
       " 'mfcc_std_2',\n",
       " 'mfcc_std_3',\n",
       " 'mfcc_std_4',\n",
       " 'mfcc_std_5',\n",
       " 'mfcc_std_6',\n",
       " 'mfcc_std_7',\n",
       " 'mfcc_std_8',\n",
       " 'mfcc_std_9',\n",
       " 'mfcc_std_10',\n",
       " 'mfcc_std_11',\n",
       " 'mfcc_std_12',\n",
       " 'mfcc_std_13',\n",
       " 'chromagram_mean_1',\n",
       " 'chromagram_mean_2',\n",
       " 'chromagram_mean_3',\n",
       " 'chromagram_mean_4',\n",
       " 'chromagram_mean_5',\n",
       " 'chromagram_mean_6',\n",
       " 'chromagram_mean_7',\n",
       " 'chromagram_mean_8',\n",
       " 'chromagram_mean_9',\n",
       " 'chromagram_mean_10',\n",
       " 'chromagram_mean_11',\n",
       " 'chromagram_mean_12',\n",
       " 'chromagram_std_1',\n",
       " 'chromagram_std_2',\n",
       " 'chromagram_std_3',\n",
       " 'chromagram_std_4',\n",
       " 'chromagram_std_5',\n",
       " 'chromagram_std_6',\n",
       " 'chromagram_std_7',\n",
       " 'chromagram_std_8',\n",
       " 'chromagram_std_9',\n",
       " 'chromagram_std_10',\n",
       " 'chromagram_std_11',\n",
       " 'chromagram_std_12',\n",
       " 'loudness_mean',\n",
       " 'loudness_std',\n",
       " 'energy_mean',\n",
       " 'energy_std',\n",
       " 'perceptual_sharp_mean',\n",
       " 'perceptual_sharp_std',\n",
       " 'spectral_slope_mean',\n",
       " 'spectral_slope_std']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of usable features\n",
    "mean_str = 'mean'\n",
    "std_str = 'std'\n",
    "num_mfcc = 13\n",
    "num_chroma = 12\n",
    "\n",
    "chroma_list = []\n",
    "mfcc_list = []\n",
    "features_list = [None] * len(features) * 2\n",
    "\n",
    "mfcc_idx = features.index('mfcc') * 2\n",
    "chroma_idx = features.index('chromagram') * 2\n",
    "\n",
    "\n",
    "for i in range(num_chroma):\n",
    "    chroma_str = f'chromagram_{mean_str}_{str(i+1)}'\n",
    "    chroma_list.append(chroma_str)\n",
    "\n",
    "for i in range(num_chroma):\n",
    "    chroma_str = f'chromagram_{std_str}_{str(i+1)}'\n",
    "    chroma_list.append(chroma_str)\n",
    "\n",
    "\n",
    "for i in range(num_mfcc):\n",
    "    mfcc_str = f'mfcc_{mean_str}_{str(i+1)}'\n",
    "    mfcc_list.append(mfcc_str)\n",
    "\n",
    "for i in range(num_mfcc):\n",
    "    mfcc_str = f'mfcc_{std_str}_{str(i+1)}'\n",
    "    mfcc_list.append(mfcc_str)\n",
    "\n",
    "mean_list = [f'{feature}_{mean_str}' for feature in features]\n",
    "std_list = [f'{feature}_{std_str}' for feature in features]\n",
    "\n",
    "features_list[::2] = mean_list\n",
    "features_list[1::2] = std_list\n",
    "\n",
    "features_list.pop(chroma_idx + 1)\n",
    "features_list.pop(chroma_idx)\n",
    "features_list[chroma_idx:chroma_idx] = chroma_list\n",
    "features_list.pop(mfcc_idx + 1)\n",
    "features_list.pop(mfcc_idx)\n",
    "features_list[mfcc_idx:mfcc_idx] = mfcc_list\n",
    "\n",
    "print(len(features_list))\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms_mean                 float32\n",
      "rms_std                  float32\n",
      "zerocross_mean           float32\n",
      "zerocross_std            float32\n",
      "rolloff_mean             float32\n",
      "                          ...   \n",
      "energy_std               float32\n",
      "perceptual_sharp_mean    float32\n",
      "perceptual_sharp_std     float32\n",
      "spectral_slope_mean      float32\n",
      "spectral_slope_std       float32\n",
      "Length: 74, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>zerocross_mean</th>\n",
       "      <th>zerocross_std</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_std</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_std</th>\n",
       "      <th>spread_mean</th>\n",
       "      <th>spread_std</th>\n",
       "      <th>...</th>\n",
       "      <th>chromagram_std_11</th>\n",
       "      <th>chromagram_std_12</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>perceptual_sharp_mean</th>\n",
       "      <th>perceptual_sharp_std</th>\n",
       "      <th>spectral_slope_mean</th>\n",
       "      <th>spectral_slope_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.115824</td>\n",
       "      <td>0.195989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.449088</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.176589</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.356061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.101282</td>\n",
       "      <td>0.133305</td>\n",
       "      <td>0.223017</td>\n",
       "      <td>0.419552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488677</td>\n",
       "      <td>0.445115</td>\n",
       "      <td>0.139904</td>\n",
       "      <td>0.240593</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.344697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>0.115822</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>0.246303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486936</td>\n",
       "      <td>0.446409</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.058544</td>\n",
       "      <td>0.180633</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.116314</td>\n",
       "      <td>0.344697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.160497</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.114858</td>\n",
       "      <td>0.195098</td>\n",
       "      <td>0.063163</td>\n",
       "      <td>0.243513</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425687</td>\n",
       "      <td>0.386710</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.076265</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.278942</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.200090</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>0.231721</td>\n",
       "      <td>0.084002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430076</td>\n",
       "      <td>0.384531</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.277877</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.076973</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>0.348198</td>\n",
       "      <td>0.204170</td>\n",
       "      <td>0.527218</td>\n",
       "      <td>0.134059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667863</td>\n",
       "      <td>0.572254</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>0.163258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.286410</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>0.289175</td>\n",
       "      <td>0.288548</td>\n",
       "      <td>0.495799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357107</td>\n",
       "      <td>0.415765</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>0.311533</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.245375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.339912</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.187232</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.147617</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464942</td>\n",
       "      <td>0.432722</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>0.190987</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.193182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.136810</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.175816</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.104899</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472617</td>\n",
       "      <td>0.411407</td>\n",
       "      <td>0.378655</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>0.136725</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.192803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.143626</td>\n",
       "      <td>0.125337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637950</td>\n",
       "      <td>0.569848</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.182074</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.194318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rms_mean   rms_std  zerocross_mean  zerocross_std  rolloff_mean  \\\n",
       "0     0.057916  0.181649        0.080720       0.321308      0.128489   \n",
       "1     0.029380  0.090423        0.078890       0.315966      0.156579   \n",
       "2     0.058108  0.181268        0.079321       0.308780      0.140393   \n",
       "3     0.034239  0.044759        0.160497       0.287264      0.292328   \n",
       "4     0.064380  0.076265        0.168180       0.278942      0.297361   \n",
       "...        ...       ...             ...            ...           ...   \n",
       "1208  0.106141  0.046720        0.206274       0.211808      0.564615   \n",
       "1209  0.077711  0.046950        0.112818       0.250360      0.286410   \n",
       "1210  0.339912  0.174158        0.045219       0.187232      0.152356   \n",
       "1211  0.136810  0.058775        0.078109       0.175816      0.172034   \n",
       "1212  0.090646  0.079490        0.045652       0.187891      0.106409   \n",
       "\n",
       "      rolloff_std  centroid_mean  centroid_std  spread_mean  spread_std  ...  \\\n",
       "0        0.121556       0.075689      0.069339     0.115824    0.195989  ...   \n",
       "1        0.222034       0.101282      0.133305     0.223017    0.419552  ...   \n",
       "2        0.199835       0.083232      0.115822     0.132058    0.246303  ...   \n",
       "3        0.114858       0.195098      0.063163     0.243513    0.084057  ...   \n",
       "4        0.113448       0.200090      0.058414     0.231721    0.084002  ...   \n",
       "...           ...            ...           ...          ...         ...  ...   \n",
       "1208     0.171320       0.348198      0.204170     0.527218    0.134059  ...   \n",
       "1209     0.432750       0.154018      0.289175     0.288548    0.495799  ...   \n",
       "1210     0.053483       0.083377      0.022200     0.147617    0.060942  ...   \n",
       "1211     0.052256       0.104899      0.037419     0.115945    0.041124  ...   \n",
       "1212     0.039075       0.068920      0.021485     0.143626    0.125337  ...   \n",
       "\n",
       "      chromagram_std_11  chromagram_std_12  loudness_mean  loudness_std  \\\n",
       "0              0.486863           0.449088       0.191118      0.347576   \n",
       "1              0.488677           0.445115       0.139904      0.240593   \n",
       "2              0.486936           0.446409       0.193484      0.344449   \n",
       "3              0.425687           0.386710       0.199732      0.199390   \n",
       "4              0.430076           0.384531       0.272825      0.277877   \n",
       "...                 ...                ...            ...           ...   \n",
       "1208           0.667863           0.572254       0.374871      0.258196   \n",
       "1209           0.357107           0.415765       0.267722      0.311533   \n",
       "1210           0.464942           0.432722       0.497385      0.659042   \n",
       "1211           0.472617           0.411407       0.378655      0.404539   \n",
       "1212           0.637950           0.569848       0.253873      0.368001   \n",
       "\n",
       "      energy_mean  energy_std  perceptual_sharp_mean  perceptual_sharp_std  \\\n",
       "0        0.058354    0.181010               0.176589              0.352935   \n",
       "1        0.029598    0.090092               0.204845              0.335579   \n",
       "2        0.058544    0.180633               0.184976              0.337910   \n",
       "3        0.034204    0.045013               0.315799              0.262805   \n",
       "4        0.064285    0.076973               0.322426              0.252839   \n",
       "...           ...         ...                    ...                   ...   \n",
       "1208     0.106127    0.048706               0.383245              0.122873   \n",
       "1209     0.077776    0.047545               0.245375              0.201658   \n",
       "1210     0.339674    0.181340               0.190987              0.162281   \n",
       "1211     0.136725    0.062171               0.202077              0.161894   \n",
       "1212     0.090647    0.080159               0.182074              0.165173   \n",
       "\n",
       "      spectral_slope_mean  spectral_slope_std  \n",
       "0                0.114804            0.356061  \n",
       "1                0.132931            0.344697  \n",
       "2                0.116314            0.344697  \n",
       "3                0.212991            0.295455  \n",
       "4                0.217523            0.291667  \n",
       "...                   ...                 ...  \n",
       "1208             0.326284            0.163258  \n",
       "1209             0.160121            0.242424  \n",
       "1210             0.096677            0.193182  \n",
       "1211             0.117825            0.192803  \n",
       "1212             0.086103            0.194318  \n",
       "\n",
       "[1213 rows x 74 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter data to accomodate available features\n",
    "f_features_norm = features_norm.filter(features_list).astype(np.float32)\n",
    "print(f_features_norm.dtypes)\n",
    "f_features_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>decreaseslope_mean</th>\n",
       "      <th>fluctuation_max</th>\n",
       "      <th>eventdensity_mean</th>\n",
       "      <th>zerocross_mean</th>\n",
       "      <th>zerocross_std</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_std</th>\n",
       "      <th>brightness_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>perceptual_sharp_mean</th>\n",
       "      <th>perceptual_sharp_std</th>\n",
       "      <th>spectral_slope_mean</th>\n",
       "      <th>spectral_slope_std</th>\n",
       "      <th>spectral_var_mean</th>\n",
       "      <th>spectral_var_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>0.206975</td>\n",
       "      <td>0.078080</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>0.256286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.176589</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.496309</td>\n",
       "      <td>0.199965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.196134</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.271329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139904</td>\n",
       "      <td>0.240593</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508387</td>\n",
       "      <td>0.214740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>0.206228</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>0.260993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.058544</td>\n",
       "      <td>0.180633</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.116314</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.500550</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.261880</td>\n",
       "      <td>0.083218</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.160497</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.114858</td>\n",
       "      <td>0.558156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.539779</td>\n",
       "      <td>0.173066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.076265</td>\n",
       "      <td>0.260347</td>\n",
       "      <td>0.087722</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.278942</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.576993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.277877</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.076973</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.540959</td>\n",
       "      <td>0.129461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.107604</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>0.588964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>0.163258</td>\n",
       "      <td>0.296059</td>\n",
       "      <td>0.119320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.286410</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.332642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>0.311533</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.245375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.453177</td>\n",
       "      <td>0.157346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.339912</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.557341</td>\n",
       "      <td>0.047963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.187232</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>0.259379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>0.190987</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.402072</td>\n",
       "      <td>0.188584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.136810</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.175816</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.385884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378655</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>0.136725</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.192803</td>\n",
       "      <td>0.371038</td>\n",
       "      <td>0.110928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>0.968749</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.216756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.182074</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.194318</td>\n",
       "      <td>0.401578</td>\n",
       "      <td>0.229771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rms_mean   rms_std  decreaseslope_mean  fluctuation_max  \\\n",
       "0     0.057916  0.181649            0.206975         0.078080   \n",
       "1     0.029380  0.090423            0.196134         0.070676   \n",
       "2     0.058108  0.181268            0.206228         0.076273   \n",
       "3     0.034239  0.044759            0.261880         0.083218   \n",
       "4     0.064380  0.076265            0.260347         0.087722   \n",
       "...        ...       ...                 ...              ...   \n",
       "1208  0.106141  0.046720            0.107604         0.043783   \n",
       "1209  0.077711  0.046950            0.123511         0.035052   \n",
       "1210  0.339912  0.174158            0.557341         0.047963   \n",
       "1211  0.136810  0.058775            0.110323         0.037463   \n",
       "1212  0.090646  0.079490            0.111319         0.037404   \n",
       "\n",
       "      eventdensity_mean  zerocross_mean  zerocross_std  rolloff_mean  \\\n",
       "0              0.180149        0.080720       0.321308      0.128489   \n",
       "1              0.180149        0.078890       0.315966      0.156579   \n",
       "2              0.180149        0.079321       0.308780      0.140393   \n",
       "3              0.340900        0.160497       0.287264      0.292328   \n",
       "4              0.843000        0.168180       0.278942      0.297361   \n",
       "...                 ...             ...            ...           ...   \n",
       "1208           1.000000        0.206274       0.211808      0.564615   \n",
       "1209           1.000000        0.112818       0.250360      0.286410   \n",
       "1210           1.000000        0.045219       0.187232      0.152356   \n",
       "1211           1.000000        0.078109       0.175816      0.172034   \n",
       "1212           0.968749        0.045652       0.187891      0.106409   \n",
       "\n",
       "      rolloff_std  brightness_mean  ...  loudness_mean  loudness_std  \\\n",
       "0        0.121556         0.256286  ...       0.191118      0.347576   \n",
       "1        0.222034         0.271329  ...       0.139904      0.240593   \n",
       "2        0.199835         0.260993  ...       0.193484      0.344449   \n",
       "3        0.114858         0.558156  ...       0.199732      0.199390   \n",
       "4        0.113448         0.576993  ...       0.272825      0.277877   \n",
       "...           ...              ...  ...            ...           ...   \n",
       "1208     0.171320         0.588964  ...       0.374871      0.258196   \n",
       "1209     0.432750         0.332642  ...       0.267722      0.311533   \n",
       "1210     0.053483         0.259379  ...       0.497385      0.659042   \n",
       "1211     0.052256         0.385884  ...       0.378655      0.404539   \n",
       "1212     0.039075         0.216756  ...       0.253873      0.368001   \n",
       "\n",
       "      energy_mean  energy_std  perceptual_sharp_mean  perceptual_sharp_std  \\\n",
       "0        0.058354    0.181010               0.176589              0.352935   \n",
       "1        0.029598    0.090092               0.204845              0.335579   \n",
       "2        0.058544    0.180633               0.184976              0.337910   \n",
       "3        0.034204    0.045013               0.315799              0.262805   \n",
       "4        0.064285    0.076973               0.322426              0.252839   \n",
       "...           ...         ...                    ...                   ...   \n",
       "1208     0.106127    0.048706               0.383245              0.122873   \n",
       "1209     0.077776    0.047545               0.245375              0.201658   \n",
       "1210     0.339674    0.181340               0.190987              0.162281   \n",
       "1211     0.136725    0.062171               0.202077              0.161894   \n",
       "1212     0.090647    0.080159               0.182074              0.165173   \n",
       "\n",
       "      spectral_slope_mean  spectral_slope_std  spectral_var_mean  \\\n",
       "0                0.114804            0.356061           0.496309   \n",
       "1                0.132931            0.344697           0.508387   \n",
       "2                0.116314            0.344697           0.500550   \n",
       "3                0.212991            0.295455           0.539779   \n",
       "4                0.217523            0.291667           0.540959   \n",
       "...                   ...                 ...                ...   \n",
       "1208             0.326284            0.163258           0.296059   \n",
       "1209             0.160121            0.242424           0.453177   \n",
       "1210             0.096677            0.193182           0.402072   \n",
       "1211             0.117825            0.192803           0.371038   \n",
       "1212             0.086103            0.194318           0.401578   \n",
       "\n",
       "      spectral_var_std  \n",
       "0             0.199965  \n",
       "1             0.214740  \n",
       "2             0.196160  \n",
       "3             0.173066  \n",
       "4             0.129461  \n",
       "...                ...  \n",
       "1208          0.119320  \n",
       "1209          0.157346  \n",
       "1210          0.188584  \n",
       "1211          0.110928  \n",
       "1212          0.229771  \n",
       "\n",
       "[1213 rows x 122 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_norm = features_norm.copy().drop('fileName',axis=1).astype(np.float32)\n",
    "all_features_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal - 10 fold cross validation\n",
      "r2:\n",
      "[0.79833813 0.83424638 0.77920394 0.75475626 0.78645611 0.78206345\n",
      " 0.77639994 0.8359521  0.82853508 0.79530494]\n",
      "MSE:\n",
      "[0.07037932 0.05027857 0.07493303 0.07457962 0.07121098 0.06580734\n",
      " 0.07599971 0.0596237  0.06221437 0.06182181]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.797126</td>\n",
       "      <td>0.026007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.066685</td>\n",
       "      <td>0.007840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std\n",
       "r2   0.797126  0.026007\n",
       "MSE  0.066685  0.007840"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test 9:1 for Arousal\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "mse = np.empty((1,0),dtype=float)\n",
    "r2 = np.empty((1,0),dtype=float)\n",
    "for train_index, test_index in kfold.split(all_features_norm):\n",
    "    train_X, test_X = all_features_norm.iloc[train_index, :], all_features_norm.iloc[test_index, :]\n",
    "    train_Y, test_Y = aro_y[train_index], aro_y[test_index]\n",
    "\n",
    "    reg = make_pipeline(SVR(kernel='rbf', gamma='auto'))\n",
    "    reg.fit(train_X, train_Y)\n",
    "\n",
    "    pred = reg.predict(test_X)\n",
    "    mse = np.append(mse, mean_squared_error(test_Y, pred))\n",
    "    r2 = np.append(r2,r2_score(test_Y, pred))\n",
    "\n",
    "print('Arousal - 10 fold cross validation')\n",
    "print('r2:')\n",
    "print(r2)\n",
    "print('MSE:')\n",
    "print(mse)\n",
    "\n",
    "aro_data = {\n",
    "    'Mean': [\n",
    "        np.mean(r2),\n",
    "        np.mean(mse)\n",
    "    ],\n",
    "    'Std': [\n",
    "        np.std(r2),\n",
    "        np.std(mse)\n",
    "    ]}\n",
    "index = ['r2', 'MSE']\n",
    "\n",
    "aro_df = pd.DataFrame(data=aro_data, index=index)\n",
    "aro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valance - 10 fold cross validation\n",
      "r2:\n",
      "[0.5168237  0.49326102 0.61070143 0.45856488 0.50863419 0.61051419\n",
      " 0.55712164 0.63993786 0.65196406 0.60111556]\n",
      "MSE:\n",
      "[0.15000648 0.16356135 0.12886895 0.17410439 0.15934735 0.1304457\n",
      " 0.12848115 0.12539751 0.11990696 0.14485105]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.564864</td>\n",
       "      <td>0.063779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.142497</td>\n",
       "      <td>0.017660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std\n",
       "r2   0.564864  0.063779\n",
       "MSE  0.142497  0.017660"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test 9:1 for Valance\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "mse = np.empty((1,0),dtype=float)\n",
    "r2 = np.empty((1,0),dtype=float)\n",
    "for train_index, test_index in kfold.split(all_features_norm):\n",
    "    train_X, test_X = all_features_norm.iloc[train_index, :], all_features_norm.iloc[test_index, :]\n",
    "    train_Y, test_Y = val_y[train_index], val_y[test_index]\n",
    "\n",
    "    reg = make_pipeline(SVR(kernel='rbf', gamma='auto'))\n",
    "    reg.fit(train_X, train_Y)\n",
    "\n",
    "    pred = reg.predict(test_X)\n",
    "    mse = np.append(mse, mean_squared_error(test_Y, pred))\n",
    "    r2 = np.append(r2,r2_score(test_Y, pred))\n",
    "\n",
    "print('Valance - 10 fold cross validation')\n",
    "print('r2:')\n",
    "print(r2)\n",
    "print('MSE:')\n",
    "print(mse)\n",
    "\n",
    "val_data = {\n",
    "    'Mean': [\n",
    "        np.mean(r2),\n",
    "        np.mean(mse)\n",
    "    ],\n",
    "    'Std': [\n",
    "        np.std(r2),\n",
    "        np.std(mse)\n",
    "    ]}\n",
    "index = ['r2', 'MSE']\n",
    "\n",
    "val_df = pd.DataFrame(data=val_data, index=index)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3bd56 th.col_heading {\n",
       "  text-align: center;\n",
       "  font-size: 1.2em;\n",
       "  font-style: italic;\n",
       "  padding: 0 3em;\n",
       "}\n",
       "#T_3bd56 th.col_heading.level0 {\n",
       "  font-style: normal;\n",
       "  font-size: 1.5em;\n",
       "}\n",
       "#T_3bd56 th.row_heading {\n",
       "  text-align: center;\n",
       "  font-size: 1.2em;\n",
       "  font-style: italic;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_3bd56 td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3bd56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3bd56_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Arousal</th>\n",
       "      <th id=\"T_3bd56_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Valance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_3bd56_level1_col0\" class=\"col_heading level1 col0\" >Mean</th>\n",
       "      <th id=\"T_3bd56_level1_col1\" class=\"col_heading level1 col1\" >Std</th>\n",
       "      <th id=\"T_3bd56_level1_col2\" class=\"col_heading level1 col2\" >Mean</th>\n",
       "      <th id=\"T_3bd56_level1_col3\" class=\"col_heading level1 col3\" >Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3bd56_level0_row0\" class=\"row_heading level0 row0\" >R square</th>\n",
       "      <td id=\"T_3bd56_row0_col0\" class=\"data row0 col0\" >0.797126</td>\n",
       "      <td id=\"T_3bd56_row0_col1\" class=\"data row0 col1\" >0.026007</td>\n",
       "      <td id=\"T_3bd56_row0_col2\" class=\"data row0 col2\" >0.564864</td>\n",
       "      <td id=\"T_3bd56_row0_col3\" class=\"data row0 col3\" >0.063779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3bd56_level0_row1\" class=\"row_heading level0 row1\" >Mean Square Error</th>\n",
       "      <td id=\"T_3bd56_row1_col0\" class=\"data row1 col0\" >0.066685</td>\n",
       "      <td id=\"T_3bd56_row1_col1\" class=\"data row1 col1\" >0.007840</td>\n",
       "      <td id=\"T_3bd56_row1_col2\" class=\"data row1 col2\" >0.142497</td>\n",
       "      <td id=\"T_3bd56_row1_col3\" class=\"data row1 col3\" >0.017660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1794063f1f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([aro_df,val_df], axis=1)\n",
    "df.index = pd.Index(['R square', 'Mean Square Error'])\n",
    "df.columns = pd.MultiIndex.from_product([['Arousal', 'Valance'],['Mean', 'Std']])\n",
    "\n",
    "s = df.style\n",
    "s.set_table_styles([\n",
    "    {'selector': 'th.col_heading', 'props': 'text-align: center; font-size: 1.2em; font-style: italic; padding: 0 3em;'},\n",
    "    {'selector': 'th.col_heading.level0', 'props': 'font-style: normal; font-size: 1.5em;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'text-align: center; font-size: 1.2em; font-style: italic; font-weight: bold;'},\n",
    "    {'selector': 'td', 'props': 'text-align: center;'},\n",
    "], overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression with lesser feature input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(122, activation='relu', input_shape=(122, 1)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(256, activation='relu',),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 0.3327 - mse: 0.3327 - val_loss: 0.3300 - val_mse: 0.3300\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.3307 - mse: 0.3307 - val_loss: 0.3505 - val_mse: 0.3505\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 1s 34ms/step - loss: 0.3300 - mse: 0.3300 - val_loss: 0.3866 - val_mse: 0.3866\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.3292 - mse: 0.3292 - val_loss: 0.3716 - val_mse: 0.3716\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 1s 24ms/step - loss: 0.3291 - mse: 0.3291 - val_loss: 0.3769 - val_mse: 0.3769\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 1s 24ms/step - loss: 0.3288 - mse: 0.3288 - val_loss: 0.3738 - val_mse: 0.3738\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.3279 - mse: 0.3279 - val_loss: 0.3769 - val_mse: 0.3769\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 0.3277 - mse: 0.3277 - val_loss: 0.3555 - val_mse: 0.3555\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 1s 28ms/step - loss: 0.3275 - mse: 0.3275 - val_loss: 0.3763 - val_mse: 0.3763\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 0.3276 - mse: 0.3276 - val_loss: 0.3767 - val_mse: 0.3767\n"
     ]
    }
   ],
   "source": [
    "test_model = model.fit(\n",
    "    all_features_norm,\n",
    "    aro_y,\n",
    "    epochs=10,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training and validation loss')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss      = test_model.history['loss']\n",
    "mse  = test_model.history['mse']\n",
    "val_loss     = test_model.history['val_loss']\n",
    "val_mse = test_model.history['val_mse']\n",
    "\n",
    "epochs   = range(len(mse)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     mse, label='Training')\n",
    "plt.plot  ( epochs, val_mse, label='Validation')\n",
    "plt.title ('Training and validation MSE')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot  ( epochs,     loss, label='Training')\n",
    "plt.plot  ( epochs, val_loss, label='Validation')\n",
    "plt.legend()\n",
    "plt.title ('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Arousal model\n",
    "\n",
    "aro_model = keras.Sequential([\n",
    "    keras.layers.Conv1D(filters=32, kernel_size=10, strides=1, activation='relu', kernel_initializer='glorot_uniform', input_shape=(74, 1)),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256, kernel_initializer='glorot_uniform', activation='relu'),\n",
    "    keras.layers.Dense(1, kernel_initializer='glorot_uniform', activation='linear')\n",
    "])\n",
    "\n",
    "aro_model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001, rho=0.000001),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=keras.metrics.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 65, 32)            352       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 65, 32)            0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 58, 32)            8224      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 58, 32)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 58, 256)           8448      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 58, 1)             257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aro_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.3680 - val_mean_squared_error: 0.3680\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3310 - mean_squared_error: 0.3310 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3307 - mean_squared_error: 0.3307 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3575 - val_mean_squared_error: 0.3575\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3673 - val_mean_squared_error: 0.3673\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3578 - val_mean_squared_error: 0.3578\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.3579 - val_mean_squared_error: 0.3579\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.3669 - val_mean_squared_error: 0.3669\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3296 - mean_squared_error: 0.3296 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.3665 - val_mean_squared_error: 0.3665\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.3662 - val_mean_squared_error: 0.3662\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3293 - mean_squared_error: 0.3293 - val_loss: 0.3660 - val_mean_squared_error: 0.3660\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3291 - mean_squared_error: 0.3291 - val_loss: 0.3662 - val_mean_squared_error: 0.3662\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3288 - mean_squared_error: 0.3288 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3664 - val_mean_squared_error: 0.3664\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3573 - val_mean_squared_error: 0.3573\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3663 - val_mean_squared_error: 0.3663\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.3570 - val_mean_squared_error: 0.3570\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.3562 - val_mean_squared_error: 0.3562\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3280 - mean_squared_error: 0.3280 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.3564 - val_mean_squared_error: 0.3564\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.3661 - val_mean_squared_error: 0.3661\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.3558 - val_mean_squared_error: 0.3558\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3272 - mean_squared_error: 0.3272 - val_loss: 0.3552 - val_mean_squared_error: 0.3552\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.3665 - val_mean_squared_error: 0.3665\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3272 - mean_squared_error: 0.3272 - val_loss: 0.3550 - val_mean_squared_error: 0.3550\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.3660 - val_mean_squared_error: 0.3660\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.3545 - val_mean_squared_error: 0.3545\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.3666 - val_mean_squared_error: 0.3666\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.3541 - val_mean_squared_error: 0.3541\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3264 - mean_squared_error: 0.3264 - val_loss: 0.3670 - val_mean_squared_error: 0.3670\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.3539 - val_mean_squared_error: 0.3539\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.3668 - val_mean_squared_error: 0.3668\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.3538 - val_mean_squared_error: 0.3538\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3255 - mean_squared_error: 0.3255 - val_loss: 0.3670 - val_mean_squared_error: 0.3670\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.3530 - val_mean_squared_error: 0.3530\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3253 - mean_squared_error: 0.3253 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3251 - mean_squared_error: 0.3251 - val_loss: 0.3528 - val_mean_squared_error: 0.3528\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3248 - mean_squared_error: 0.3248 - val_loss: 0.3679 - val_mean_squared_error: 0.3679\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.3529 - val_mean_squared_error: 0.3529\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.3681 - val_mean_squared_error: 0.3681\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3244 - mean_squared_error: 0.3244 - val_loss: 0.3525 - val_mean_squared_error: 0.3525\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.3685 - val_mean_squared_error: 0.3685\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.3523 - val_mean_squared_error: 0.3523\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.3683 - val_mean_squared_error: 0.3683\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.3517 - val_mean_squared_error: 0.3517\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.3684 - val_mean_squared_error: 0.3684\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3238 - mean_squared_error: 0.3238 - val_loss: 0.3516 - val_mean_squared_error: 0.3516\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3233 - mean_squared_error: 0.3233 - val_loss: 0.3686 - val_mean_squared_error: 0.3686\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.3689 - val_mean_squared_error: 0.3689\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3231 - mean_squared_error: 0.3231 - val_loss: 0.3688 - val_mean_squared_error: 0.3688\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.3511 - val_mean_squared_error: 0.3511\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.3687 - val_mean_squared_error: 0.3687\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3229 - mean_squared_error: 0.3229 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3223 - mean_squared_error: 0.3223 - val_loss: 0.3693 - val_mean_squared_error: 0.3693\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3229 - mean_squared_error: 0.3229 - val_loss: 0.3509 - val_mean_squared_error: 0.3509\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3224 - mean_squared_error: 0.3224 - val_loss: 0.3690 - val_mean_squared_error: 0.3690\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3694 - val_mean_squared_error: 0.3694\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3220 - mean_squared_error: 0.3220 - val_loss: 0.3504 - val_mean_squared_error: 0.3504\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3216 - mean_squared_error: 0.3216 - val_loss: 0.3696 - val_mean_squared_error: 0.3696\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3215 - mean_squared_error: 0.3215 - val_loss: 0.3506 - val_mean_squared_error: 0.3506\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3697 - val_mean_squared_error: 0.3697\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3219 - mean_squared_error: 0.3219 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3211 - mean_squared_error: 0.3211 - val_loss: 0.3704 - val_mean_squared_error: 0.3704\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.3502 - val_mean_squared_error: 0.3502\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.3501 - val_mean_squared_error: 0.3501\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3206 - mean_squared_error: 0.3206 - val_loss: 0.3499 - val_mean_squared_error: 0.3499\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3199 - mean_squared_error: 0.3199 - val_loss: 0.3705 - val_mean_squared_error: 0.3705\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3204 - mean_squared_error: 0.3204 - val_loss: 0.3498 - val_mean_squared_error: 0.3498\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.3202 - mean_squared_error: 0.3202 - val_loss: 0.3706 - val_mean_squared_error: 0.3706\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.3497 - val_mean_squared_error: 0.3497\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.3496 - val_mean_squared_error: 0.3496\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3196 - mean_squared_error: 0.3196 - val_loss: 0.3495 - val_mean_squared_error: 0.3495\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3199 - mean_squared_error: 0.3199 - val_loss: 0.3493 - val_mean_squared_error: 0.3493\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.3708 - val_mean_squared_error: 0.3708\n"
     ]
    }
   ],
   "source": [
    "history = aro_model.fit(\n",
    "    f_features_norm,\n",
    "    aro_y,\n",
    "    epochs=100,\n",
    "    batch_size=1213,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Valence model\n",
    "\n",
    "val_model = keras.Sequential()\n",
    "# First convolution layer\n",
    "val_model.add(keras.layers.Conv1D(filters=8, kernel_size=5, strides=1, activation='relu', kernel_initializer='glorot_uniform', input_shape=(1213, 74)))\n",
    "val_model.add(keras.layers.MaxPool1D(2))\n",
    "val_model.add(keras.layers.Dropout(0.15))\n",
    "\n",
    "# Second convolution layer\n",
    "val_model.add(keras.layers.Conv1D(filters=8, kernel_size=3, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "val_model.add(keras.layers.MaxPool1D(2))\n",
    "val_model.add(keras.layers.Dropout(0.15))\n",
    "\n",
    "# Fully connected layer\n",
    "val_model.add(keras.layers.Dense(256, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "val_model.add(keras.layers.Dense(1, kernel_initializer='glorot_uniform', activation='linear'))\n",
    "\n",
    "val_model.compile(optimizer=keras.optimizers.RMSprop(learning_rate=0.001, rho=0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.Sequential()\n",
    "# First convolution layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(8, (5,5), 1, activation='relu', kernel_initializer='glorot_uniform', input_shape=(54, 30, 1)))\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.15))\n",
    "\n",
    "# Second convolution layer\n",
    "cnn_model.add(tf.keras.layers.Conv2D(8, (3,3), activation='relu', kernel_initializer='glorot_uniform'))\n",
    "cnn_model.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "cnn_model.add(tf.keras.layers.Dropout(0.15))\n",
    "\n",
    "# Flatten results to feed into DNN\n",
    "cnn_model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "cnn_model.add(tf.keras.layers.Dense(256, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "cnn_model.add(tf.keras.layers.Dense(1, kernel_initializer='glorot_uniform', activation='linear'))\n",
    "\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
