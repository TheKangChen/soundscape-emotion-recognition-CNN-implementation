{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Using TensorFlow Version:  2.8.0\n",
      "• Using TensorFlow Version:  0.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import RandomFourierFeatures\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflowjs as tfjs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('\\u2022 Using TensorFlow Version: ', tf.__version__)\n",
    "print('\\u2022 Using TensorFlow Version: ', tfa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders & Paths\n",
    "audio_path = './audio/'\n",
    "\n",
    "features_path = './features/Normalized_Features.csv'\n",
    "\n",
    "truth_path = './truth/ratings/'\n",
    "aro_truth_path = truth_path + 'Arousal.csv'\n",
    "val_truth_path = truth_path + 'Valence.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_norm = pd.read_csv(features_path)\n",
    "aro_truth = pd.read_csv(aro_truth_path, header=None)\n",
    "val_truth = pd.read_csv(val_truth_path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>decreaseslope_mean</th>\n",
       "      <th>fluctuation_max</th>\n",
       "      <th>eventdensity_mean</th>\n",
       "      <th>zerocross_mean</th>\n",
       "      <th>zerocross_std</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_std</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>perceptual_sharp_mean</th>\n",
       "      <th>perceptual_sharp_std</th>\n",
       "      <th>spectral_slope_mean</th>\n",
       "      <th>spectral_slope_std</th>\n",
       "      <th>spectral_var_mean</th>\n",
       "      <th>spectral_var_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_between_human_indicator_1-12_1-6.wav</td>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>0.206975</td>\n",
       "      <td>0.078080</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.176589</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.496309</td>\n",
       "      <td>0.199965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-12.wav</td>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.196134</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139904</td>\n",
       "      <td>0.240593</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508387</td>\n",
       "      <td>0.214740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-6.wav</td>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>0.206228</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.058544</td>\n",
       "      <td>0.180633</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.116314</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.500550</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_between_human_indicator_2-12_2-6.wav</td>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.261880</td>\n",
       "      <td>0.083218</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.160497</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.114858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.539779</td>\n",
       "      <td>0.173066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_between_human_indicator_2-6_2-12.wav</td>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.076265</td>\n",
       "      <td>0.260347</td>\n",
       "      <td>0.087722</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.278942</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.277877</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.076973</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.540959</td>\n",
       "      <td>0.129461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>r_5indicator59071_8556-hq.wav</td>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.107604</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>0.163258</td>\n",
       "      <td>0.296059</td>\n",
       "      <td>0.119320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>r_6mechanical60455_27178-hq.wav</td>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.286410</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>0.311533</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.245375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.453177</td>\n",
       "      <td>0.157346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r_6mechanical66618_800302-hq.wav</td>\n",
       "      <td>0.339912</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.557340</td>\n",
       "      <td>0.047963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.187232</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>0.190987</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.402072</td>\n",
       "      <td>0.188584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>r_7mechanical54899_170972-hq.wav</td>\n",
       "      <td>0.136810</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.175816</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378655</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>0.136725</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.192803</td>\n",
       "      <td>0.371038</td>\n",
       "      <td>0.110928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>r_8indicator262210_4415905-hq.wav</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>0.968749</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.182074</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.194318</td>\n",
       "      <td>0.401578</td>\n",
       "      <td>0.229771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      fileName  rms_mean   rms_std  \\\n",
       "0     mix_between_human_indicator_1-12_1-6.wav  0.057916  0.181649   \n",
       "1     mix_between_human_indicator_1-6_1-12.wav  0.029380  0.090423   \n",
       "2      mix_between_human_indicator_1-6_1-6.wav  0.058108  0.181268   \n",
       "3     mix_between_human_indicator_2-12_2-6.wav  0.034239  0.044759   \n",
       "4     mix_between_human_indicator_2-6_2-12.wav  0.064380  0.076265   \n",
       "...                                        ...       ...       ...   \n",
       "1208             r_5indicator59071_8556-hq.wav  0.106141  0.046720   \n",
       "1209           r_6mechanical60455_27178-hq.wav  0.077711  0.046950   \n",
       "1210          r_6mechanical66618_800302-hq.wav  0.339912  0.174158   \n",
       "1211          r_7mechanical54899_170972-hq.wav  0.136810  0.058775   \n",
       "1212         r_8indicator262210_4415905-hq.wav  0.090646  0.079490   \n",
       "\n",
       "      decreaseslope_mean  fluctuation_max  eventdensity_mean  zerocross_mean  \\\n",
       "0               0.206975         0.078080           0.180149        0.080720   \n",
       "1               0.196134         0.070676           0.180149        0.078890   \n",
       "2               0.206228         0.076273           0.180149        0.079321   \n",
       "3               0.261880         0.083218           0.340900        0.160497   \n",
       "4               0.260347         0.087722           0.843000        0.168180   \n",
       "...                  ...              ...                ...             ...   \n",
       "1208            0.107604         0.043783           1.000000        0.206274   \n",
       "1209            0.123511         0.035052           1.000000        0.112818   \n",
       "1210            0.557340         0.047963           1.000000        0.045219   \n",
       "1211            0.110323         0.037463           1.000000        0.078109   \n",
       "1212            0.111319         0.037404           0.968749        0.045652   \n",
       "\n",
       "      zerocross_std  rolloff_mean  rolloff_std  ...  loudness_mean  \\\n",
       "0          0.321308      0.128489     0.121556  ...       0.191118   \n",
       "1          0.315966      0.156579     0.222034  ...       0.139904   \n",
       "2          0.308780      0.140393     0.199835  ...       0.193484   \n",
       "3          0.287264      0.292328     0.114858  ...       0.199732   \n",
       "4          0.278942      0.297361     0.113448  ...       0.272825   \n",
       "...             ...           ...          ...  ...            ...   \n",
       "1208       0.211808      0.564615     0.171320  ...       0.374871   \n",
       "1209       0.250360      0.286410     0.432750  ...       0.267722   \n",
       "1210       0.187232      0.152356     0.053483  ...       0.497385   \n",
       "1211       0.175816      0.172034     0.052256  ...       0.378655   \n",
       "1212       0.187891      0.106409     0.039075  ...       0.253873   \n",
       "\n",
       "      loudness_std  energy_mean  energy_std  perceptual_sharp_mean  \\\n",
       "0         0.347576     0.058354    0.181010               0.176589   \n",
       "1         0.240593     0.029598    0.090092               0.204845   \n",
       "2         0.344449     0.058544    0.180633               0.184976   \n",
       "3         0.199390     0.034204    0.045013               0.315799   \n",
       "4         0.277877     0.064285    0.076973               0.322426   \n",
       "...            ...          ...         ...                    ...   \n",
       "1208      0.258196     0.106127    0.048706               0.383245   \n",
       "1209      0.311533     0.077776    0.047545               0.245375   \n",
       "1210      0.659042     0.339674    0.181340               0.190987   \n",
       "1211      0.404539     0.136725    0.062171               0.202077   \n",
       "1212      0.368001     0.090647    0.080159               0.182074   \n",
       "\n",
       "      perceptual_sharp_std  spectral_slope_mean  spectral_slope_std  \\\n",
       "0                 0.352935             0.114804            0.356061   \n",
       "1                 0.335579             0.132931            0.344697   \n",
       "2                 0.337910             0.116314            0.344697   \n",
       "3                 0.262805             0.212991            0.295455   \n",
       "4                 0.252839             0.217523            0.291667   \n",
       "...                    ...                  ...                 ...   \n",
       "1208              0.122873             0.326284            0.163258   \n",
       "1209              0.201658             0.160121            0.242424   \n",
       "1210              0.162281             0.096677            0.193182   \n",
       "1211              0.161894             0.117825            0.192803   \n",
       "1212              0.165173             0.086103            0.194318   \n",
       "\n",
       "      spectral_var_mean  spectral_var_std  \n",
       "0              0.496309          0.199965  \n",
       "1              0.508387          0.214740  \n",
       "2              0.500550          0.196160  \n",
       "3              0.539779          0.173066  \n",
       "4              0.540959          0.129461  \n",
       "...                 ...               ...  \n",
       "1208           0.296059          0.119320  \n",
       "1209           0.453177          0.157346  \n",
       "1210           0.402072          0.188584  \n",
       "1211           0.371038          0.110928  \n",
       "1212           0.401578          0.229771  \n",
       "\n",
       "[1213 rows x 123 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized features statistics\n",
    "features_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_between_human_indicator_1-12_1-6.wav</td>\n",
       "      <td>0.523495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-12.wav</td>\n",
       "      <td>0.211871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-6.wav</td>\n",
       "      <td>0.589448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_between_human_indicator_2-12_2-6.wav</td>\n",
       "      <td>0.396538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_between_human_indicator_2-6_2-12.wav</td>\n",
       "      <td>0.764221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>r_5indicator59071_8556-hq.wav</td>\n",
       "      <td>0.902721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>r_6mechanical60455_27178-hq.wav</td>\n",
       "      <td>0.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r_6mechanical66618_800302-hq.wav</td>\n",
       "      <td>0.968673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>r_7mechanical54899_170972-hq.wav</td>\n",
       "      <td>0.812036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>r_8indicator262210_4415905-hq.wav</td>\n",
       "      <td>0.927453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0         1\n",
       "0     mix_between_human_indicator_1-12_1-6.wav  0.523495\n",
       "1     mix_between_human_indicator_1-6_1-12.wav  0.211871\n",
       "2      mix_between_human_indicator_1-6_1-6.wav  0.589448\n",
       "3     mix_between_human_indicator_2-12_2-6.wav  0.396538\n",
       "4     mix_between_human_indicator_2-6_2-12.wav  0.764221\n",
       "...                                        ...       ...\n",
       "1208             r_5indicator59071_8556-hq.wav  0.902721\n",
       "1209           r_6mechanical60455_27178-hq.wav  0.655400\n",
       "1210          r_6mechanical66618_800302-hq.wav  0.968673\n",
       "1211          r_7mechanical54899_170972-hq.wav  0.812036\n",
       "1212         r_8indicator262210_4415905-hq.wav  0.927453\n",
       "\n",
       "[1213 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arousal ground truth ratings\n",
    "aro_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.523495\n",
       "1       0.211871\n",
       "2       0.589448\n",
       "3       0.396538\n",
       "4       0.764221\n",
       "          ...   \n",
       "1208    0.902721\n",
       "1209    0.655400\n",
       "1210    0.968673\n",
       "1211    0.812036\n",
       "1212    0.927453\n",
       "Name: 1, Length: 1213, dtype: float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aro_y = aro_truth[1].astype(np.float32)\n",
    "aro_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mix_between_human_indicator_1-12_1-6.wav</td>\n",
       "      <td>-0.767519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-12.wav</td>\n",
       "      <td>-0.577906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mix_between_human_indicator_1-6_1-6.wav</td>\n",
       "      <td>-0.752679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mix_between_human_indicator_2-12_2-6.wav</td>\n",
       "      <td>0.526793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mix_between_human_indicator_2-6_2-12.wav</td>\n",
       "      <td>-0.190437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>r_5indicator59071_8556-hq.wav</td>\n",
       "      <td>-0.952185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>r_6mechanical60455_27178-hq.wav</td>\n",
       "      <td>-0.742786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>r_6mechanical66618_800302-hq.wav</td>\n",
       "      <td>-0.965375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>r_7mechanical54899_170972-hq.wav</td>\n",
       "      <td>0.022259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>r_8indicator262210_4415905-hq.wav</td>\n",
       "      <td>-0.592745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0         1\n",
       "0     mix_between_human_indicator_1-12_1-6.wav -0.767519\n",
       "1     mix_between_human_indicator_1-6_1-12.wav -0.577906\n",
       "2      mix_between_human_indicator_1-6_1-6.wav -0.752679\n",
       "3     mix_between_human_indicator_2-12_2-6.wav  0.526793\n",
       "4     mix_between_human_indicator_2-6_2-12.wav -0.190437\n",
       "...                                        ...       ...\n",
       "1208             r_5indicator59071_8556-hq.wav -0.952185\n",
       "1209           r_6mechanical60455_27178-hq.wav -0.742786\n",
       "1210          r_6mechanical66618_800302-hq.wav -0.965375\n",
       "1211          r_7mechanical54899_170972-hq.wav  0.022259\n",
       "1212         r_8indicator262210_4415905-hq.wav -0.592745\n",
       "\n",
       "[1213 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valence ground truth ratings\n",
    "val_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.767519\n",
       "1      -0.577906\n",
       "2      -0.752679\n",
       "3       0.526793\n",
       "4      -0.190437\n",
       "          ...   \n",
       "1208   -0.952185\n",
       "1209   -0.742786\n",
       "1210   -0.965375\n",
       "1211    0.022259\n",
       "1212   -0.592745\n",
       "Name: 1, Length: 1213, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y = val_truth[1].astype(np.float32)\n",
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1213\n"
     ]
    }
   ],
   "source": [
    "files_list = features_norm['fileName'].tolist()\n",
    "print(f'Number of files: {len(files_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 14\n"
     ]
    }
   ],
   "source": [
    "# Meyda extractable features\n",
    "features = ['rms','zerocross','rolloff','centroid','spread','skewness','kurtosis','flatness','mfcc','chromagram','loudness','energy','perceptual_sharp','spectral_slope']\n",
    "# meyda_available_features = ['rms','zcr','spectralRolloff','spectralCentroid','spectralSpread','spectralSkewness','spectralKurtosis','spectralFlatness','mfcc','chroma','loudness','energy','perceptualSharpness','spectralSlope']\n",
    "\n",
    "print(f'Number of features: {len(features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rms_mean',\n",
       " 'rms_std',\n",
       " 'zerocross_mean',\n",
       " 'zerocross_std',\n",
       " 'rolloff_mean',\n",
       " 'rolloff_std',\n",
       " 'centroid_mean',\n",
       " 'centroid_std',\n",
       " 'spread_mean',\n",
       " 'spread_std',\n",
       " 'skewness_mean',\n",
       " 'skewness_std',\n",
       " 'kurtosis_mean',\n",
       " 'kurtosis_std',\n",
       " 'flatness_mean',\n",
       " 'flatness_std',\n",
       " 'mfcc_mean_1',\n",
       " 'mfcc_mean_2',\n",
       " 'mfcc_mean_3',\n",
       " 'mfcc_mean_4',\n",
       " 'mfcc_mean_5',\n",
       " 'mfcc_mean_6',\n",
       " 'mfcc_mean_7',\n",
       " 'mfcc_mean_8',\n",
       " 'mfcc_mean_9',\n",
       " 'mfcc_mean_10',\n",
       " 'mfcc_mean_11',\n",
       " 'mfcc_mean_12',\n",
       " 'mfcc_mean_13',\n",
       " 'mfcc_std_1',\n",
       " 'mfcc_std_2',\n",
       " 'mfcc_std_3',\n",
       " 'mfcc_std_4',\n",
       " 'mfcc_std_5',\n",
       " 'mfcc_std_6',\n",
       " 'mfcc_std_7',\n",
       " 'mfcc_std_8',\n",
       " 'mfcc_std_9',\n",
       " 'mfcc_std_10',\n",
       " 'mfcc_std_11',\n",
       " 'mfcc_std_12',\n",
       " 'mfcc_std_13',\n",
       " 'chromagram_mean_1',\n",
       " 'chromagram_mean_2',\n",
       " 'chromagram_mean_3',\n",
       " 'chromagram_mean_4',\n",
       " 'chromagram_mean_5',\n",
       " 'chromagram_mean_6',\n",
       " 'chromagram_mean_7',\n",
       " 'chromagram_mean_8',\n",
       " 'chromagram_mean_9',\n",
       " 'chromagram_mean_10',\n",
       " 'chromagram_mean_11',\n",
       " 'chromagram_mean_12',\n",
       " 'chromagram_std_1',\n",
       " 'chromagram_std_2',\n",
       " 'chromagram_std_3',\n",
       " 'chromagram_std_4',\n",
       " 'chromagram_std_5',\n",
       " 'chromagram_std_6',\n",
       " 'chromagram_std_7',\n",
       " 'chromagram_std_8',\n",
       " 'chromagram_std_9',\n",
       " 'chromagram_std_10',\n",
       " 'chromagram_std_11',\n",
       " 'chromagram_std_12',\n",
       " 'loudness_mean',\n",
       " 'loudness_std',\n",
       " 'energy_mean',\n",
       " 'energy_std',\n",
       " 'perceptual_sharp_mean',\n",
       " 'perceptual_sharp_std',\n",
       " 'spectral_slope_mean',\n",
       " 'spectral_slope_std']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of usable features\n",
    "mean_str = 'mean'\n",
    "std_str = 'std'\n",
    "num_mfcc = 13\n",
    "num_chroma = 12\n",
    "\n",
    "chroma_list = []\n",
    "mfcc_list = []\n",
    "features_list = [None] * len(features) * 2\n",
    "\n",
    "mfcc_idx = features.index('mfcc') * 2\n",
    "chroma_idx = features.index('chromagram') * 2\n",
    "\n",
    "\n",
    "for i in range(num_chroma):\n",
    "    chroma_str = f'chromagram_{mean_str}_{str(i+1)}'\n",
    "    chroma_list.append(chroma_str)\n",
    "\n",
    "for i in range(num_chroma):\n",
    "    chroma_str = f'chromagram_{std_str}_{str(i+1)}'\n",
    "    chroma_list.append(chroma_str)\n",
    "\n",
    "\n",
    "for i in range(num_mfcc):\n",
    "    mfcc_str = f'mfcc_{mean_str}_{str(i+1)}'\n",
    "    mfcc_list.append(mfcc_str)\n",
    "\n",
    "for i in range(num_mfcc):\n",
    "    mfcc_str = f'mfcc_{std_str}_{str(i+1)}'\n",
    "    mfcc_list.append(mfcc_str)\n",
    "\n",
    "mean_list = [f'{feature}_{mean_str}' for feature in features]\n",
    "std_list = [f'{feature}_{std_str}' for feature in features]\n",
    "\n",
    "features_list[::2] = mean_list\n",
    "features_list[1::2] = std_list\n",
    "\n",
    "features_list.pop(chroma_idx + 1)\n",
    "features_list.pop(chroma_idx)\n",
    "features_list[chroma_idx:chroma_idx] = chroma_list\n",
    "features_list.pop(mfcc_idx + 1)\n",
    "features_list.pop(mfcc_idx)\n",
    "features_list[mfcc_idx:mfcc_idx] = mfcc_list\n",
    "\n",
    "print(len(features_list))\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rms_mean                 float32\n",
      "rms_std                  float32\n",
      "zerocross_mean           float32\n",
      "zerocross_std            float32\n",
      "rolloff_mean             float32\n",
      "                          ...   \n",
      "energy_std               float32\n",
      "perceptual_sharp_mean    float32\n",
      "perceptual_sharp_std     float32\n",
      "spectral_slope_mean      float32\n",
      "spectral_slope_std       float32\n",
      "Length: 74, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>zerocross_mean</th>\n",
       "      <th>zerocross_std</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_std</th>\n",
       "      <th>centroid_mean</th>\n",
       "      <th>centroid_std</th>\n",
       "      <th>spread_mean</th>\n",
       "      <th>spread_std</th>\n",
       "      <th>...</th>\n",
       "      <th>chromagram_std_11</th>\n",
       "      <th>chromagram_std_12</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>perceptual_sharp_mean</th>\n",
       "      <th>perceptual_sharp_std</th>\n",
       "      <th>spectral_slope_mean</th>\n",
       "      <th>spectral_slope_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>0.075689</td>\n",
       "      <td>0.069339</td>\n",
       "      <td>0.115824</td>\n",
       "      <td>0.195989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486863</td>\n",
       "      <td>0.449088</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.176589</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.356061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.101282</td>\n",
       "      <td>0.133305</td>\n",
       "      <td>0.223017</td>\n",
       "      <td>0.419552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488677</td>\n",
       "      <td>0.445115</td>\n",
       "      <td>0.139904</td>\n",
       "      <td>0.240593</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.344697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>0.083232</td>\n",
       "      <td>0.115822</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>0.246303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486936</td>\n",
       "      <td>0.446409</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.058544</td>\n",
       "      <td>0.180633</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.116314</td>\n",
       "      <td>0.344697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.160497</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.114858</td>\n",
       "      <td>0.195098</td>\n",
       "      <td>0.063163</td>\n",
       "      <td>0.243513</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425687</td>\n",
       "      <td>0.386710</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.076265</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.278942</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.200090</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>0.231721</td>\n",
       "      <td>0.084002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430076</td>\n",
       "      <td>0.384531</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.277877</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.076973</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>0.348198</td>\n",
       "      <td>0.204170</td>\n",
       "      <td>0.527218</td>\n",
       "      <td>0.134059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.667863</td>\n",
       "      <td>0.572254</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>0.163258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.286410</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>0.289175</td>\n",
       "      <td>0.288548</td>\n",
       "      <td>0.495799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357107</td>\n",
       "      <td>0.415765</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>0.311533</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.245375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.242424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.339912</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.187232</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>0.083377</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.147617</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464942</td>\n",
       "      <td>0.432722</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>0.190987</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.193182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.136810</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.175816</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.104899</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.115945</td>\n",
       "      <td>0.041124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472617</td>\n",
       "      <td>0.411407</td>\n",
       "      <td>0.378655</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>0.136725</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.192803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.068920</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.143626</td>\n",
       "      <td>0.125337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637950</td>\n",
       "      <td>0.569848</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.182074</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.194318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rms_mean   rms_std  zerocross_mean  zerocross_std  rolloff_mean  \\\n",
       "0     0.057916  0.181649        0.080720       0.321308      0.128489   \n",
       "1     0.029380  0.090423        0.078890       0.315966      0.156579   \n",
       "2     0.058108  0.181268        0.079321       0.308780      0.140393   \n",
       "3     0.034239  0.044759        0.160497       0.287264      0.292328   \n",
       "4     0.064380  0.076265        0.168180       0.278942      0.297361   \n",
       "...        ...       ...             ...            ...           ...   \n",
       "1208  0.106141  0.046720        0.206274       0.211808      0.564615   \n",
       "1209  0.077711  0.046950        0.112818       0.250360      0.286410   \n",
       "1210  0.339912  0.174158        0.045219       0.187232      0.152356   \n",
       "1211  0.136810  0.058775        0.078109       0.175816      0.172034   \n",
       "1212  0.090646  0.079490        0.045652       0.187891      0.106409   \n",
       "\n",
       "      rolloff_std  centroid_mean  centroid_std  spread_mean  spread_std  ...  \\\n",
       "0        0.121556       0.075689      0.069339     0.115824    0.195989  ...   \n",
       "1        0.222034       0.101282      0.133305     0.223017    0.419552  ...   \n",
       "2        0.199835       0.083232      0.115822     0.132058    0.246303  ...   \n",
       "3        0.114858       0.195098      0.063163     0.243513    0.084057  ...   \n",
       "4        0.113448       0.200090      0.058414     0.231721    0.084002  ...   \n",
       "...           ...            ...           ...          ...         ...  ...   \n",
       "1208     0.171320       0.348198      0.204170     0.527218    0.134059  ...   \n",
       "1209     0.432750       0.154018      0.289175     0.288548    0.495799  ...   \n",
       "1210     0.053483       0.083377      0.022200     0.147617    0.060942  ...   \n",
       "1211     0.052256       0.104899      0.037419     0.115945    0.041124  ...   \n",
       "1212     0.039075       0.068920      0.021485     0.143626    0.125337  ...   \n",
       "\n",
       "      chromagram_std_11  chromagram_std_12  loudness_mean  loudness_std  \\\n",
       "0              0.486863           0.449088       0.191118      0.347576   \n",
       "1              0.488677           0.445115       0.139904      0.240593   \n",
       "2              0.486936           0.446409       0.193484      0.344449   \n",
       "3              0.425687           0.386710       0.199732      0.199390   \n",
       "4              0.430076           0.384531       0.272825      0.277877   \n",
       "...                 ...                ...            ...           ...   \n",
       "1208           0.667863           0.572254       0.374871      0.258196   \n",
       "1209           0.357107           0.415765       0.267722      0.311533   \n",
       "1210           0.464942           0.432722       0.497385      0.659042   \n",
       "1211           0.472617           0.411407       0.378655      0.404539   \n",
       "1212           0.637950           0.569848       0.253873      0.368001   \n",
       "\n",
       "      energy_mean  energy_std  perceptual_sharp_mean  perceptual_sharp_std  \\\n",
       "0        0.058354    0.181010               0.176589              0.352935   \n",
       "1        0.029598    0.090092               0.204845              0.335579   \n",
       "2        0.058544    0.180633               0.184976              0.337910   \n",
       "3        0.034204    0.045013               0.315799              0.262805   \n",
       "4        0.064285    0.076973               0.322426              0.252839   \n",
       "...           ...         ...                    ...                   ...   \n",
       "1208     0.106127    0.048706               0.383245              0.122873   \n",
       "1209     0.077776    0.047545               0.245375              0.201658   \n",
       "1210     0.339674    0.181340               0.190987              0.162281   \n",
       "1211     0.136725    0.062171               0.202077              0.161894   \n",
       "1212     0.090647    0.080159               0.182074              0.165173   \n",
       "\n",
       "      spectral_slope_mean  spectral_slope_std  \n",
       "0                0.114804            0.356061  \n",
       "1                0.132931            0.344697  \n",
       "2                0.116314            0.344697  \n",
       "3                0.212991            0.295455  \n",
       "4                0.217523            0.291667  \n",
       "...                   ...                 ...  \n",
       "1208             0.326284            0.163258  \n",
       "1209             0.160121            0.242424  \n",
       "1210             0.096677            0.193182  \n",
       "1211             0.117825            0.192803  \n",
       "1212             0.086103            0.194318  \n",
       "\n",
       "[1213 rows x 74 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter data to accomodate available features\n",
    "f_features_norm = features_norm.filter(features_list).astype(np.float32)\n",
    "print(f_features_norm.dtypes)\n",
    "f_features_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_std</th>\n",
       "      <th>decreaseslope_mean</th>\n",
       "      <th>fluctuation_max</th>\n",
       "      <th>eventdensity_mean</th>\n",
       "      <th>zerocross_mean</th>\n",
       "      <th>zerocross_std</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>rolloff_std</th>\n",
       "      <th>brightness_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness_mean</th>\n",
       "      <th>loudness_std</th>\n",
       "      <th>energy_mean</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>perceptual_sharp_mean</th>\n",
       "      <th>perceptual_sharp_std</th>\n",
       "      <th>spectral_slope_mean</th>\n",
       "      <th>spectral_slope_std</th>\n",
       "      <th>spectral_var_mean</th>\n",
       "      <th>spectral_var_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.181649</td>\n",
       "      <td>0.206975</td>\n",
       "      <td>0.078080</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.080720</td>\n",
       "      <td>0.321308</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>0.256286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191118</td>\n",
       "      <td>0.347576</td>\n",
       "      <td>0.058354</td>\n",
       "      <td>0.181010</td>\n",
       "      <td>0.176589</td>\n",
       "      <td>0.352935</td>\n",
       "      <td>0.114804</td>\n",
       "      <td>0.356061</td>\n",
       "      <td>0.496309</td>\n",
       "      <td>0.199965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029380</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.196134</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.078890</td>\n",
       "      <td>0.315966</td>\n",
       "      <td>0.156579</td>\n",
       "      <td>0.222034</td>\n",
       "      <td>0.271329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139904</td>\n",
       "      <td>0.240593</td>\n",
       "      <td>0.029598</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>0.204845</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.132931</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.508387</td>\n",
       "      <td>0.214740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.058108</td>\n",
       "      <td>0.181268</td>\n",
       "      <td>0.206228</td>\n",
       "      <td>0.076273</td>\n",
       "      <td>0.180149</td>\n",
       "      <td>0.079321</td>\n",
       "      <td>0.308780</td>\n",
       "      <td>0.140393</td>\n",
       "      <td>0.199835</td>\n",
       "      <td>0.260993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193484</td>\n",
       "      <td>0.344449</td>\n",
       "      <td>0.058544</td>\n",
       "      <td>0.180633</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.116314</td>\n",
       "      <td>0.344697</td>\n",
       "      <td>0.500550</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034239</td>\n",
       "      <td>0.044759</td>\n",
       "      <td>0.261880</td>\n",
       "      <td>0.083218</td>\n",
       "      <td>0.340900</td>\n",
       "      <td>0.160497</td>\n",
       "      <td>0.287264</td>\n",
       "      <td>0.292328</td>\n",
       "      <td>0.114858</td>\n",
       "      <td>0.558156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199732</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.045013</td>\n",
       "      <td>0.315799</td>\n",
       "      <td>0.262805</td>\n",
       "      <td>0.212991</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.539779</td>\n",
       "      <td>0.173066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064380</td>\n",
       "      <td>0.076265</td>\n",
       "      <td>0.260347</td>\n",
       "      <td>0.087722</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.278942</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>0.113448</td>\n",
       "      <td>0.576993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272825</td>\n",
       "      <td>0.277877</td>\n",
       "      <td>0.064285</td>\n",
       "      <td>0.076973</td>\n",
       "      <td>0.322426</td>\n",
       "      <td>0.252839</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.540959</td>\n",
       "      <td>0.129461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.106141</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.107604</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206274</td>\n",
       "      <td>0.211808</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.171320</td>\n",
       "      <td>0.588964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.374871</td>\n",
       "      <td>0.258196</td>\n",
       "      <td>0.106127</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>0.326284</td>\n",
       "      <td>0.163258</td>\n",
       "      <td>0.296059</td>\n",
       "      <td>0.119320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.046950</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112818</td>\n",
       "      <td>0.250360</td>\n",
       "      <td>0.286410</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.332642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267722</td>\n",
       "      <td>0.311533</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.245375</td>\n",
       "      <td>0.201658</td>\n",
       "      <td>0.160121</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.453177</td>\n",
       "      <td>0.157346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.339912</td>\n",
       "      <td>0.174158</td>\n",
       "      <td>0.557341</td>\n",
       "      <td>0.047963</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045219</td>\n",
       "      <td>0.187232</td>\n",
       "      <td>0.152356</td>\n",
       "      <td>0.053483</td>\n",
       "      <td>0.259379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.659042</td>\n",
       "      <td>0.339674</td>\n",
       "      <td>0.181340</td>\n",
       "      <td>0.190987</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.402072</td>\n",
       "      <td>0.188584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.136810</td>\n",
       "      <td>0.058775</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078109</td>\n",
       "      <td>0.175816</td>\n",
       "      <td>0.172034</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.385884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378655</td>\n",
       "      <td>0.404539</td>\n",
       "      <td>0.136725</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.117825</td>\n",
       "      <td>0.192803</td>\n",
       "      <td>0.371038</td>\n",
       "      <td>0.110928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.079490</td>\n",
       "      <td>0.111319</td>\n",
       "      <td>0.037404</td>\n",
       "      <td>0.968749</td>\n",
       "      <td>0.045652</td>\n",
       "      <td>0.187891</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>0.216756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.368001</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.080159</td>\n",
       "      <td>0.182074</td>\n",
       "      <td>0.165173</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>0.194318</td>\n",
       "      <td>0.401578</td>\n",
       "      <td>0.229771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rms_mean   rms_std  decreaseslope_mean  fluctuation_max  \\\n",
       "0     0.057916  0.181649            0.206975         0.078080   \n",
       "1     0.029380  0.090423            0.196134         0.070676   \n",
       "2     0.058108  0.181268            0.206228         0.076273   \n",
       "3     0.034239  0.044759            0.261880         0.083218   \n",
       "4     0.064380  0.076265            0.260347         0.087722   \n",
       "...        ...       ...                 ...              ...   \n",
       "1208  0.106141  0.046720            0.107604         0.043783   \n",
       "1209  0.077711  0.046950            0.123511         0.035052   \n",
       "1210  0.339912  0.174158            0.557341         0.047963   \n",
       "1211  0.136810  0.058775            0.110323         0.037463   \n",
       "1212  0.090646  0.079490            0.111319         0.037404   \n",
       "\n",
       "      eventdensity_mean  zerocross_mean  zerocross_std  rolloff_mean  \\\n",
       "0              0.180149        0.080720       0.321308      0.128489   \n",
       "1              0.180149        0.078890       0.315966      0.156579   \n",
       "2              0.180149        0.079321       0.308780      0.140393   \n",
       "3              0.340900        0.160497       0.287264      0.292328   \n",
       "4              0.843000        0.168180       0.278942      0.297361   \n",
       "...                 ...             ...            ...           ...   \n",
       "1208           1.000000        0.206274       0.211808      0.564615   \n",
       "1209           1.000000        0.112818       0.250360      0.286410   \n",
       "1210           1.000000        0.045219       0.187232      0.152356   \n",
       "1211           1.000000        0.078109       0.175816      0.172034   \n",
       "1212           0.968749        0.045652       0.187891      0.106409   \n",
       "\n",
       "      rolloff_std  brightness_mean  ...  loudness_mean  loudness_std  \\\n",
       "0        0.121556         0.256286  ...       0.191118      0.347576   \n",
       "1        0.222034         0.271329  ...       0.139904      0.240593   \n",
       "2        0.199835         0.260993  ...       0.193484      0.344449   \n",
       "3        0.114858         0.558156  ...       0.199732      0.199390   \n",
       "4        0.113448         0.576993  ...       0.272825      0.277877   \n",
       "...           ...              ...  ...            ...           ...   \n",
       "1208     0.171320         0.588964  ...       0.374871      0.258196   \n",
       "1209     0.432750         0.332642  ...       0.267722      0.311533   \n",
       "1210     0.053483         0.259379  ...       0.497385      0.659042   \n",
       "1211     0.052256         0.385884  ...       0.378655      0.404539   \n",
       "1212     0.039075         0.216756  ...       0.253873      0.368001   \n",
       "\n",
       "      energy_mean  energy_std  perceptual_sharp_mean  perceptual_sharp_std  \\\n",
       "0        0.058354    0.181010               0.176589              0.352935   \n",
       "1        0.029598    0.090092               0.204845              0.335579   \n",
       "2        0.058544    0.180633               0.184976              0.337910   \n",
       "3        0.034204    0.045013               0.315799              0.262805   \n",
       "4        0.064285    0.076973               0.322426              0.252839   \n",
       "...           ...         ...                    ...                   ...   \n",
       "1208     0.106127    0.048706               0.383245              0.122873   \n",
       "1209     0.077776    0.047545               0.245375              0.201658   \n",
       "1210     0.339674    0.181340               0.190987              0.162281   \n",
       "1211     0.136725    0.062171               0.202077              0.161894   \n",
       "1212     0.090647    0.080159               0.182074              0.165173   \n",
       "\n",
       "      spectral_slope_mean  spectral_slope_std  spectral_var_mean  \\\n",
       "0                0.114804            0.356061           0.496309   \n",
       "1                0.132931            0.344697           0.508387   \n",
       "2                0.116314            0.344697           0.500550   \n",
       "3                0.212991            0.295455           0.539779   \n",
       "4                0.217523            0.291667           0.540959   \n",
       "...                   ...                 ...                ...   \n",
       "1208             0.326284            0.163258           0.296059   \n",
       "1209             0.160121            0.242424           0.453177   \n",
       "1210             0.096677            0.193182           0.402072   \n",
       "1211             0.117825            0.192803           0.371038   \n",
       "1212             0.086103            0.194318           0.401578   \n",
       "\n",
       "      spectral_var_std  \n",
       "0             0.199965  \n",
       "1             0.214740  \n",
       "2             0.196160  \n",
       "3             0.173066  \n",
       "4             0.129461  \n",
       "...                ...  \n",
       "1208          0.119320  \n",
       "1209          0.157346  \n",
       "1210          0.188584  \n",
       "1211          0.110928  \n",
       "1212          0.229771  \n",
       "\n",
       "[1213 rows x 122 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features_norm = features_norm.copy().drop('fileName',axis=1).astype(np.float32)\n",
    "all_features_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal - 10 fold cross validation\n",
      "r2:\n",
      "[0.81573141 0.75441118 0.80490381 0.83386745 0.84318671 0.7499544\n",
      " 0.7694012  0.81525508 0.77523311 0.77517342]\n",
      "MSE:\n",
      "[0.05708745 0.07520305 0.0583616  0.06001713 0.05486512 0.08394502\n",
      " 0.0717186  0.0672347  0.06647909 0.07793994]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.793712</td>\n",
       "      <td>0.031416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.009299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std\n",
       "r2   0.793712  0.031416\n",
       "MSE  0.067285  0.009299"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test 9:1 for Arousal\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "mse = np.empty((1,0),dtype=float)\n",
    "r2 = np.empty((1,0),dtype=float)\n",
    "for train_index, test_index in kfold.split(all_features_norm):\n",
    "    train_X, test_X = all_features_norm.iloc[train_index, :], all_features_norm.iloc[test_index, :]\n",
    "    train_Y, test_Y = aro_y[train_index], aro_y[test_index]\n",
    "\n",
    "    reg = make_pipeline(SVR(kernel='rbf', gamma='auto'))\n",
    "    reg.fit(train_X, train_Y)\n",
    "\n",
    "    pred = reg.predict(test_X)\n",
    "    mse = np.append(mse, mean_squared_error(test_Y, pred))\n",
    "    r2 = np.append(r2,r2_score(test_Y, pred))\n",
    "\n",
    "print('Arousal - 10 fold cross validation')\n",
    "print('r2:')\n",
    "print(r2)\n",
    "print('MSE:')\n",
    "print(mse)\n",
    "\n",
    "aro_data = {\n",
    "    'Mean': [\n",
    "        np.mean(r2),\n",
    "        np.mean(mse)\n",
    "    ],\n",
    "    'Std': [\n",
    "        np.std(r2),\n",
    "        np.std(mse)\n",
    "    ]}\n",
    "index = ['r2', 'MSE']\n",
    "\n",
    "aro_df = pd.DataFrame(data=aro_data, index=index)\n",
    "aro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valance - 10 fold cross validation\n",
      "r2:\n",
      "[0.61088377 0.60018638 0.56163316 0.46159772 0.57098077 0.617035\n",
      " 0.54270048 0.51850338 0.61494057 0.52700861]\n",
      "MSE:\n",
      "[0.14375515 0.12826027 0.13997943 0.1788558  0.15120166 0.12293315\n",
      " 0.13811416 0.14643341 0.14104119 0.14257247]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.562547</td>\n",
       "      <td>0.048298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.143315</td>\n",
       "      <td>0.014217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std\n",
       "r2   0.562547  0.048298\n",
       "MSE  0.143315  0.014217"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test 9:1 for Valance\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "mse = np.empty((1,0),dtype=float)\n",
    "r2 = np.empty((1,0),dtype=float)\n",
    "for train_index, test_index in kfold.split(all_features_norm):\n",
    "    train_X, test_X = all_features_norm.iloc[train_index, :], all_features_norm.iloc[test_index, :]\n",
    "    train_Y, test_Y = val_y[train_index], val_y[test_index]\n",
    "\n",
    "    reg = make_pipeline(SVR(kernel='rbf', gamma='auto'))\n",
    "    reg.fit(train_X, train_Y)\n",
    "\n",
    "    pred = reg.predict(test_X)\n",
    "    mse = np.append(mse, mean_squared_error(test_Y, pred))\n",
    "    r2 = np.append(r2,r2_score(test_Y, pred))\n",
    "\n",
    "print('Valance - 10 fold cross validation')\n",
    "print('r2:')\n",
    "print(r2)\n",
    "print('MSE:')\n",
    "print(mse)\n",
    "\n",
    "val_data = {\n",
    "    'Mean': [\n",
    "        np.mean(r2),\n",
    "        np.mean(mse)\n",
    "    ],\n",
    "    'Std': [\n",
    "        np.std(r2),\n",
    "        np.std(mse)\n",
    "    ]}\n",
    "index = ['r2', 'MSE']\n",
    "\n",
    "val_df = pd.DataFrame(data=val_data, index=index)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_66724 th.col_heading {\n",
       "  text-align: center;\n",
       "  font-size: 1.2em;\n",
       "  font-style: italic;\n",
       "  padding: 0 3em;\n",
       "}\n",
       "#T_66724 th.col_heading.level0 {\n",
       "  font-style: normal;\n",
       "  font-size: 1.5em;\n",
       "}\n",
       "#T_66724 th.row_heading {\n",
       "  text-align: center;\n",
       "  font-size: 1.2em;\n",
       "  font-style: italic;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_66724 td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_66724\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_66724_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Arousal</th>\n",
       "      <th id=\"T_66724_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Valance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_66724_level1_col0\" class=\"col_heading level1 col0\" >Mean</th>\n",
       "      <th id=\"T_66724_level1_col1\" class=\"col_heading level1 col1\" >Std</th>\n",
       "      <th id=\"T_66724_level1_col2\" class=\"col_heading level1 col2\" >Mean</th>\n",
       "      <th id=\"T_66724_level1_col3\" class=\"col_heading level1 col3\" >Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_66724_level0_row0\" class=\"row_heading level0 row0\" >R square</th>\n",
       "      <td id=\"T_66724_row0_col0\" class=\"data row0 col0\" >0.793712</td>\n",
       "      <td id=\"T_66724_row0_col1\" class=\"data row0 col1\" >0.031416</td>\n",
       "      <td id=\"T_66724_row0_col2\" class=\"data row0 col2\" >0.562547</td>\n",
       "      <td id=\"T_66724_row0_col3\" class=\"data row0 col3\" >0.048298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66724_level0_row1\" class=\"row_heading level0 row1\" >Mean Square Error</th>\n",
       "      <td id=\"T_66724_row1_col0\" class=\"data row1 col0\" >0.067285</td>\n",
       "      <td id=\"T_66724_row1_col1\" class=\"data row1 col1\" >0.009299</td>\n",
       "      <td id=\"T_66724_row1_col2\" class=\"data row1 col2\" >0.143315</td>\n",
       "      <td id=\"T_66724_row1_col3\" class=\"data row1 col3\" >0.014217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ba36aeb760>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([aro_df,val_df], axis=1)\n",
    "df.index = pd.Index(['R square', 'Mean Square Error'])\n",
    "df.columns = pd.MultiIndex.from_product([['Arousal', 'Valance'],['Mean', 'Std']])\n",
    "\n",
    "s = df.style\n",
    "s.set_table_styles([\n",
    "    {'selector': 'th.col_heading', 'props': 'text-align: center; font-size: 1.2em; font-style: italic; padding: 0 3em;'},\n",
    "    {'selector': 'th.col_heading.level0', 'props': 'font-style: normal; font-size: 1.5em;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'text-align: center; font-size: 1.2em; font-style: italic; font-weight: bold;'},\n",
    "    {'selector': 'td', 'props': 'text-align: center;'},\n",
    "], overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Split: 1\n",
      "KFold Split: 2\n",
      "KFold Split: 3\n",
      "KFold Split: 4\n",
      "KFold Split: 5\n",
      "KFold Split: 6\n",
      "KFold Split: 7\n",
      "KFold Split: 8\n",
      "KFold Split: 9\n",
      "KFold Split: 10\n",
      "Arousal - 10 fold cross validation\n",
      "r2:\n",
      "[0.79999381 0.84611666 0.80006604 0.87250454 0.89079326 0.84823627\n",
      " 0.82088652 0.82184211 0.0023064  0.66301542]\n",
      "MSE:\n",
      "[0.04924814 0.04279658 0.04283566 0.03259261 0.02752992 0.06006974\n",
      " 0.07283065 0.0612637  0.13440681 0.1087968 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.736576</td>\n",
       "      <td>0.251738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.063237</td>\n",
       "      <td>0.032389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std\n",
       "r2   0.736576  0.251738\n",
       "MSE  0.063237  0.032389"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Arousal Neural Net\n",
    "kfold = KFold(n_splits=10)\n",
    "k = 0\n",
    "r2 = np.empty((1,0),dtype=float)\n",
    "mse = np.empty((1,0),dtype=float)\n",
    "\n",
    "for train_index, test_index in kfold.split(all_features_norm):\n",
    "    k += 1\n",
    "    print(f'KFold Split: {k}')\n",
    "    train_X, test_X = all_features_norm.iloc[train_index, :], all_features_norm.iloc[test_index, :]\n",
    "    train_Y, test_Y = aro_y[train_index], aro_y[test_index]\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_X, test_Y))\n",
    "    SHUFFLE_BUFFER_SIZE = 121\n",
    "\n",
    "    BATCH_SIZE = 1\n",
    "    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    aro_model = keras.Sequential([\n",
    "        keras.layers.Dense(50, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(20, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    aro_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    aro_model.fit(train_dataset, epochs=10, verbose=0)\n",
    "    pred = aro_model.predict(test_X)\n",
    "    r2 = np.append(r2,r2_score(test_Y, pred))\n",
    "    mse = np.append(mse, mean_squared_error(test_Y, pred))\n",
    "    \n",
    "print('Arousal - 10 fold cross validation')\n",
    "print('r2:')\n",
    "print(r2)\n",
    "print('MSE:')\n",
    "print(mse)\n",
    "\n",
    "aro_data = {\n",
    "    'Mean': [\n",
    "        np.mean(r2),\n",
    "        np.mean(mse)\n",
    "    ],\n",
    "    'Std': [\n",
    "        np.std(r2),\n",
    "        np.std(mse)\n",
    "    ]}\n",
    "index = ['r2', 'MSE']\n",
    "\n",
    "epochs = range(len(mse))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(epochs, mse, label='MSE')\n",
    "plt.xlabel('KFold Split')\n",
    "plt.title('MSE')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(epochs, r2, label='r2')\n",
    "plt.xlabel('KFold Split')\n",
    "plt.title('r2')\n",
    "\n",
    "aro_df = pd.DataFrame(data=aro_data, index=index)\n",
    "aro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold Split: 1\n",
      "KFold Split: 2\n",
      "KFold Split: 3\n",
      "KFold Split: 4\n",
      "KFold Split: 5\n",
      "KFold Split: 6\n",
      "KFold Split: 7\n",
      "KFold Split: 8\n",
      "KFold Split: 9\n",
      "KFold Split: 10\n",
      "Valance - 10 fold cross validation\n",
      "r2:\n",
      "[0.64038448 0.64751923 0.60444365 0.48820632 0.37328859 0.31359619\n",
      " 0.39323817 0.40064442 0.41740017 0.37968552]\n",
      "MSE:\n",
      "[0.12151106 0.09823751 0.12876166 0.13533178 0.17904471 0.146963\n",
      " 0.15794021 0.24174367 0.12765306 0.15782045]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.465841</td>\n",
       "      <td>0.115853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.149501</td>\n",
       "      <td>0.037481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std\n",
       "r2   0.465841  0.115853\n",
       "MSE  0.149501  0.037481"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAJcCAYAAABuRrQKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeJUlEQVR4nO3df6zdd33f8dcbm7QUKqgWD3VxwFFr2LyWAvVSVqS2Aioly5RMgq3JaFUquqxVXdioGGar0JTtj5ROrGWzUFOgQi1dyrIOeY1HWgGb9gsWAyngpNm84BJnIAwFWraKkPa9P3xC7xw79/re45xrvx8P6Srn+zkfnfO+f5zEefr7/Z7q7gAAAABwaXvSqgcAAAAA4MITgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAzqGqvqGq3lFVv19Vf1RV91TVtaueCwBgM0QgAIBz+8YkDyb5/iRPT/KzSd5TVXtWORQAwGbsXPUAAADbSVWdSPK2JK9M8twkT+3uRxZP/1ZVfSrJdyc5sZIBAQA2yZlAAACPdVOS65I8Y00ASlU9M8lzkhxb1WAAAJvlTCAAgMd6a3c/uHahqp6c5N1J3tXdv7easQAANs+ZQAAAj3VmAHpSkl9N8nCSAyuZCABgi5wJBADwWP3og6qqJO9I8swkf627v7ayqQAAtkAEAgB4fG9L8peSvKy7/3jVwwAAbJbLwQAAzqGqnp3k7yZ5fpLPVtVXFj+vXO1kAADnr7p7/V0AAAAAXNScCQQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwwMq+Iv7yyy/vPXv2rOrtAQAAAC45H/nIRz7f3bvO9tzKItCePXty9OjRVb09AAAAwCWnqn7/XM+5HAwAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGCAnaseAC6kPQfvXPUIl4wTt1636hEAAADYAmcCAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAM4NvBlsA3UC2Pb6ACAACAC8OZQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAAD7NzIpqq6JskvJtmR5O3dfetZ9vytJP84SSf53e7+20ucE7gE7Tl456pHuGScuPW6VY8AAABsc+tGoKrakeRQkh9McjLJ3VV1uLvvXbNnb5I3Jnlxd3+xqv78hRoYAAAAgPO3kcvBrk5yvLsf6O6Hk9ye5IYz9vydJIe6+4tJ0t2fW+6YAAAAAGzFRiLQFUkeXHN8crG21nOSPKeq/ktVfWhx+dhjVNXNVXW0qo6eOnVqcxMDAAAAcN6WdWPonUn2JvmBJDcl+eWqesaZm7r7tu7e3937d+3ataS3BgAAAGA9G4lADyW5cs3x7sXaWieTHO7ur3X3p5L8j5yOQgAAAABsAxuJQHcn2VtVV1XVZUluTHL4jD3vzemzgFJVl+f05WEPLG9MAAAAALZi3QjU3Y8kOZDkriT3JXlPdx+rqluq6vrFtruSfKGq7k3ywSSv7+4vXKihAQAAADg/635FfJJ095EkR85Ye9Oax53kdYsfAAAAALaZZd0YGgAAAIBtTAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABhABAIAAAAYQAQCAAAAGGBDEaiqrqmq+6vqeFUdPMvzr6qqU1V1z+Lnx5c/KgAAAACbtXO9DVW1I8mhJD+Y5GSSu6vqcHffe8bW3+juAxdgRgAAAAC2aCNnAl2d5Hh3P9DdDye5PckNF3YsAAAAAJZpIxHoiiQPrjk+uVg708ur6uNVdUdVXXm2F6qqm6vqaFUdPXXq1CbGBQAAAGAzlnVj6H+XZE93Py/J7yR519k2dfdt3b2/u/fv2rVrSW8NAAAAwHo2EoEeSrL2zJ7di7Wv6+4vdPdXF4dvT/LdyxkPAAAAgGXYSAS6O8neqrqqqi5LcmOSw2s3VNW3rjm8Psl9yxsRAAAAgK1a99vBuvuRqjqQ5K4kO5K8s7uPVdUtSY529+Ekr6mq65M8kuQPkrzqAs4MAAAAwHlaNwIlSXcfSXLkjLU3rXn8xiRvXO5oAAAAACzLsm4MDQAAAMA2JgIBAAAADCACAQAAAAywoXsCATDLnoN3rnqES8aJW69b9QgAAJDEmUAAAAAAI4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAPsXPUAAAAAbF97Dt656hEuGSduvW7VIzCcM4EAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABthQBKqqa6rq/qo6XlUHH2ffy6uqq2r/8kYEAAAAYKvWjUBVtSPJoSTXJtmX5Kaq2neWfd+c5LVJPrzsIQEAAADYmp0b2HN1kuPd/UCSVNXtSW5Icu8Z+/5Jkp9L8vqlTggAAFzS9hy8c9UjXDJO3HrdqkcAtrGNXA52RZIH1xyfXKx9XVW9MMmV3f24//auqpur6mhVHT116tR5DwsAAADA5mz5xtBV9aQkb0nyM+vt7e7bunt/d+/ftWvXVt8aAAAAgA3aSAR6KMmVa453L9Ye9c1JviPJf6iqE0lelOSwm0MDAAAAbB8biUB3J9lbVVdV1WVJbkxy+NEnu/vL3X15d+/p7j1JPpTk+u4+ekEmBgAAAOC8rRuBuvuRJAeS3JXkviTv6e5jVXVLVV1/oQcEAAAAYOs28u1g6e4jSY6csfamc+z9ga2PBQAAy+UbqJbHN1ABXJy2fGNoAAAAALY/EQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGAAEQgAAABgABEIAAAAYAARCAAAAGCAnaseAAAAANicPQfvXPUIl4QTt1636hGeEM4EAgAAABhABAIAAAAYQAQCAAAAGEAEAgAAABjAjaEB4CLjBpDLM+UmkAAAiTOBAAAAAEYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAG2LnqAQAALhV7Dt656hEuGSduvW7VIwDAJceZQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADiEAAAAAAA4hAAAAAAAOIQAAAAAADbCgCVdU1VXV/VR2vqoNnef4nquoTVXVPVf3nqtq3/FEBAAAA2Kx1I1BV7UhyKMm1SfYluekskefXu/s7u/v5Sd6c5C3LHhQAAACAzdvImUBXJzne3Q9098NJbk9yw9oN3f2Haw6fmqSXNyIAAAAAW7VzA3uuSPLgmuOTSb7nzE1V9VNJXpfksiQvOdsLVdXNSW5Okmc961nnOysAAAAAm7S0G0N396Hu/rYkb0jys+fYc1t37+/u/bt27VrWWwMAAACwjo1EoIeSXLnmePdi7VxuT/I3tjATAAAAAEu2kQh0d5K9VXVVVV2W5MYkh9duqKq9aw6vS/I/lzciAAAAAFu17j2BuvuRqjqQ5K4kO5K8s7uPVdUtSY529+EkB6rqZUm+luSLSX70Qg4NAAAAwPnZyI2h091Hkhw5Y+1Nax6/dslzAQAAALBES7sxNAAAAADblwgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMMCGIlBVXVNV91fV8ao6eJbnX1dV91bVx6vq/VX17OWPCgAAAMBmrRuBqmpHkkNJrk2yL8lNVbXvjG0fS7K/u5+X5I4kb172oAAAAABs3kbOBLo6yfHufqC7H05ye5Ib1m7o7g929/9dHH4oye7ljgkAAADAVmwkAl2R5ME1xycXa+fy6iT//mxPVNXNVXW0qo6eOnVq41MCAAAAsCVLvTF0Vf1wkv1Jfv5sz3f3bd29v7v379q1a5lvDQAAAMDj2LmBPQ8luXLN8e7F2v+nql6W5B8l+f7u/upyxgMAAABgGTZyJtDdSfZW1VVVdVmSG5McXruhql6Q5JeSXN/dn1v+mAAAAABsxboRqLsfSXIgyV1J7kvynu4+VlW3VNX1i20/n+RpSf51Vd1TVYfP8XIAAAAArMBGLgdLdx9JcuSMtTetefyyJc8FAAAAwBIt9cbQAAAAAGxPIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAACIQAAAAwAAiEAAAAMAAIhAAAADAABuKQFV1TVXdX1XHq+rgWZ7/vqr6aFU9UlWvWP6YAAAAAGzFuhGoqnYkOZTk2iT7ktxUVfvO2PbpJK9K8uvLHhAAAACArdu5gT1XJzne3Q8kSVXdnuSGJPc+uqG7Tyye+9MLMCMAAAAAW7SRy8GuSPLgmuOTi7XzVlU3V9XRqjp66tSpzbwEAAAAAJvwhN4Yurtv6+793b1/165dT+RbAwAAAIy2kQj0UJIr1xzvXqwBAAAAcJHYSAS6O8neqrqqqi5LcmOSwxd2LAAAAACWad0I1N2PJDmQ5K4k9yV5T3cfq6pbqur6JKmqv1JVJ5P8zSS/VFXHLuTQAAAAAJyfjXw7WLr7SJIjZ6y9ac3ju3P6MjEAAAAAtqEn9MbQAAAAAKyGCAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwwIYiUFVdU1X3V9Xxqjp4lue/oap+Y/H8h6tqz9InBQAAAGDT1o1AVbUjyaEk1ybZl+Smqtp3xrZXJ/lid397kn+e5OeWPSgAAAAAm7eRM4GuTnK8ux/o7oeT3J7khjP23JDkXYvHdyR5aVXV8sYEAAAAYCuqux9/Q9UrklzT3T++OP6RJN/T3QfW7PnkYs/JxfH/Wuz5/BmvdXOSmxeHz01y/7J+EdZ1eZLPr7sLOJPPDmyOzw5sjs8ObI7PDvyZZ3f3rrM9sfOJnKK7b0ty2xP5npxWVUe7e/+q54CLjc8ObI7PDmyOzw5sjs8ObMxGLgd7KMmVa453L9bOuqeqdiZ5epIvLGNAAAAAALZuIxHo7iR7q+qqqrosyY1JDp+x53CSH108fkWSD/R615kBAAAA8IRZ93Kw7n6kqg4kuSvJjiTv7O5jVXVLkqPdfTjJO5L8alUdT/IHOR2K2F5chgeb47MDm+OzA5vjswOb47MDG7DujaEBAAAAuPht5HIwAAAAAC5yIhAAAADAACLQAFV1TVXdX1XHq+rgqueBi0FVXVlVH6yqe6vqWFW9dtUzwcWkqnZU1ceq6rdWPQtcLKrqGVV1R1X9XlXdV1V/ddUzwcWgqv7+4s9rn6yqf1VV37jqmWC7EoEucVW1I8mhJNcm2Zfkpqrat9qp4KLwSJKf6e59SV6U5Kd8duC8vDbJfaseAi4yv5jkfd39F5N8V3yGYF1VdUWS1yTZ393fkdNfZuSLiuAcRKBL39VJjnf3A939cJLbk9yw4plg2+vuz3T3RxeP/yin/yB+xWqngotDVe1Ocl2St696FrhYVNXTk3xfTn/rbrr74e7+0kqHgovHziRPqaqdSb4pyf9e8TywbYlAl74rkjy45vhk/I8snJeq2pPkBUk+vOJR4GLxC0n+QZI/XfEccDG5KsmpJL+yuJTy7VX11FUPBdtddz+U5J8l+XSSzyT5cnf/9mqngu1LBAJ4HFX1tCT/Jsnf6+4/XPU8sN1V1V9P8rnu/siqZ4GLzM4kL0zytu5+QZL/k8S9HGEdVfUtOX2lw1VJ/kKSp1bVD692Kti+RKBL30NJrlxzvHuxBqyjqp6c0wHo3d39m6ueBy4SL05yfVWdyOlLkF9SVb+22pHgonAyycnufvSs0ztyOgoBj+9lST7V3ae6+2tJfjPJ9654Jti2RKBL391J9lbVVVV1WU7fJO3wimeCba+qKqfvy3Bfd79l1fPAxaK739jdu7t7T07/N+cD3e1vZGEd3f3ZJA9W1XMXSy9Ncu8KR4KLxaeTvKiqvmnx57eXxk3V4Zx2rnoALqzufqSqDiS5K6fvlP/O7j624rHgYvDiJD+S5BNVdc9i7R9295HVjQTAJe6nk7x78Rd3DyT5sRXPA9ted3+4qu5I8tGc/nbXjyW5bbVTwfZV3b3qGQAAAAC4wFwOBgAAADCACAQAAAAwgAgEAAAAMIAIBAAAADCACAQAAAAwgAgEAFzSqupPquqeNT8Hl/jae6rqk8t6PQCAC2nnqgcAALjA/ri7n7/qIQAAVs2ZQADASFV1oqreXFWfqKr/XlXfvljfU1UfqKqPV9X7q+pZi/VnVtW/rarfXfx87+KldlTVL1fVsar67ap6ymL/a6rq3sXr3L6iXxMA4OtEIADgUveUMy4H+6E1z325u78zyb9M8guLtX+R5F3d/bwk707y1sX6W5P8x+7+riQvTHJssb43yaHu/stJvpTk5Yv1g0lesHidn7gwvxoAwMZVd696BgCAC6aqvtLdTzvL+okkL+nuB6rqyUk+291/rqo+n+Rbu/tri/XPdPflVXUqye7u/uqa19iT5He6e+/i+A1Jntzd/7Sq3pfkK0nem+S93f2VC/yrAgA8LmcCAQCT9Tken4+vrnn8J/mzey5el+RQTp81dHdVuRcjALBSIhAAMNkPrfnnf1s8/q9Jblw8fmWS/7R4/P4kP5kkVbWjqp5+rhetqiclubK7P5jkDUmenuQxZyMBADyR/I0UAHCpe0pV3bPm+H3d/ejXxH9LVX08p8/muWmx9tNJfqWqXp/kVJIfW6y/NsltVfXqnD7j5yeTfOYc77kjya8tQlEleWt3f2lJvw8AwKa4JxAAMNLinkD7u/vzq54FAOCJ4HIwAAAAgAGcCQQAAAAwgDOBAAAAAAYQgQAAAAAGEIEAAAAABhCBAAAAAAYQgQAAAAAG+H+/WjRTulpl6gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Valance Neural Net\n",
    "kfold = KFold(n_splits=10)\n",
    "k = 0\n",
    "r2 = np.empty((1,0),dtype=float)\n",
    "mse = np.empty((1,0),dtype=float)\n",
    "\n",
    "for train_index, test_index in kfold.split(all_features_norm):\n",
    "    k += 1\n",
    "    print(f'KFold Split: {k}')\n",
    "    train_X, test_X = all_features_norm.iloc[train_index, :], all_features_norm.iloc[test_index, :]\n",
    "    train_Y, test_Y = val_y[train_index], val_y[test_index]\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_X, train_Y))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_X, test_Y))\n",
    "    SHUFFLE_BUFFER_SIZE = 121\n",
    "\n",
    "    BATCH_SIZE = 1\n",
    "    train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "    val_model = keras.Sequential([\n",
    "        keras.layers.Dense(50, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(20, activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "\n",
    "    val_model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=['mse']\n",
    "    )\n",
    "\n",
    "    val_model.fit(train_dataset, epochs=10, verbose=0)\n",
    "    pred = val_model.predict(test_X)\n",
    "    r2 = np.append(r2,r2_score(test_Y, pred))\n",
    "    mse = np.append(mse, mean_squared_error(test_Y, pred))\n",
    "    \n",
    "print('Valance - 10 fold cross validation')\n",
    "print('r2:')\n",
    "print(r2)\n",
    "print('MSE:')\n",
    "print(mse)\n",
    "\n",
    "val_data = {\n",
    "    'Mean': [\n",
    "        np.mean(r2),\n",
    "        np.mean(mse)\n",
    "    ],\n",
    "    'Std': [\n",
    "        np.std(r2),\n",
    "        np.std(mse)\n",
    "    ]}\n",
    "index = ['r2', 'MSE']\n",
    "\n",
    "epochs = range(len(mse))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(epochs, mse, label='MSE')\n",
    "plt.xlabel('KFold Split')\n",
    "plt.title('MSE')\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(epochs, r2, label='r2')\n",
    "plt.xlabel('KFold Split')\n",
    "plt.title('r2')\n",
    "\n",
    "val_df = pd.DataFrame(data=val_data, index=index)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17436 th.col_heading {\n",
       "  text-align: center;\n",
       "  font-size: 1.2em;\n",
       "  font-style: italic;\n",
       "  padding: 0 3em;\n",
       "}\n",
       "#T_17436 th.col_heading.level0 {\n",
       "  font-style: normal;\n",
       "  font-size: 1.5em;\n",
       "}\n",
       "#T_17436 th.row_heading {\n",
       "  text-align: center;\n",
       "  font-size: 1.2em;\n",
       "  font-style: italic;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_17436 td {\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17436\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17436_level0_col0\" class=\"col_heading level0 col0\" colspan=\"2\">Arousal</th>\n",
       "      <th id=\"T_17436_level0_col2\" class=\"col_heading level0 col2\" colspan=\"2\">Valance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"blank level1\" >&nbsp;</th>\n",
       "      <th id=\"T_17436_level1_col0\" class=\"col_heading level1 col0\" >Mean</th>\n",
       "      <th id=\"T_17436_level1_col1\" class=\"col_heading level1 col1\" >Std</th>\n",
       "      <th id=\"T_17436_level1_col2\" class=\"col_heading level1 col2\" >Mean</th>\n",
       "      <th id=\"T_17436_level1_col3\" class=\"col_heading level1 col3\" >Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17436_level0_row0\" class=\"row_heading level0 row0\" >R square</th>\n",
       "      <td id=\"T_17436_row0_col0\" class=\"data row0 col0\" >0.736576</td>\n",
       "      <td id=\"T_17436_row0_col1\" class=\"data row0 col1\" >0.251738</td>\n",
       "      <td id=\"T_17436_row0_col2\" class=\"data row0 col2\" >0.465841</td>\n",
       "      <td id=\"T_17436_row0_col3\" class=\"data row0 col3\" >0.115853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17436_level0_row1\" class=\"row_heading level0 row1\" >Mean Square Error</th>\n",
       "      <td id=\"T_17436_row1_col0\" class=\"data row1 col0\" >0.063237</td>\n",
       "      <td id=\"T_17436_row1_col1\" class=\"data row1 col1\" >0.032389</td>\n",
       "      <td id=\"T_17436_row1_col2\" class=\"data row1 col2\" >0.149501</td>\n",
       "      <td id=\"T_17436_row1_col3\" class=\"data row1 col3\" >0.037481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ba45c746a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([aro_df,val_df], axis=1)\n",
    "df.index = pd.Index(['R square', 'Mean Square Error'])\n",
    "df.columns = pd.MultiIndex.from_product([['Arousal', 'Valance'],['Mean', 'Std']])\n",
    "\n",
    "s = df.style\n",
    "s.set_table_styles([\n",
    "    {'selector': 'th.col_heading', 'props': 'text-align: center; font-size: 1.2em; font-style: italic; padding: 0 3em;'},\n",
    "    {'selector': 'th.col_heading.level0', 'props': 'font-style: normal; font-size: 1.5em;'},\n",
    "    {'selector': 'th.row_heading', 'props': 'text-align: center; font-size: 1.2em; font-style: italic; font-weight: bold;'},\n",
    "    {'selector': 'td', 'props': 'text-align: center;'},\n",
    "], overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression with lesser feature input\n",
    "Remove features to support features available in Meyda js\\\n",
    "meyda_available_features = ['rms','zcr','spectralRolloff','spectralCentroid','spectralSpread','spectralSkewness','spectralKurtosis','spectralFlatness','mfcc','chroma','loudness','energy','perceptualSharpness','spectralSlope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net with lesser feature input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Arousal model\n",
    "\n",
    "aro_model = keras.Sequential([\n",
    "    keras.layers.Conv1D(filters=32, kernel_size=10, strides=1, activation='relu', kernel_initializer='glorot_uniform', input_shape=(74, 1)),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "    keras.layers.MaxPool1D(2),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256, kernel_initializer='glorot_uniform', activation='relu'),\n",
    "    keras.layers.Dense(1, kernel_initializer='glorot_uniform', activation='linear')\n",
    "])\n",
    "\n",
    "aro_model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=0.001, rho=0.000001),\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    metrics=keras.metrics.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 65, 32)            352       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 65, 32)            0         \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 58, 32)            8224      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 58, 32)            0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 58, 256)           8448      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 58, 1)             257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "aro_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.3680 - val_mean_squared_error: 0.3680\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3310 - mean_squared_error: 0.3310 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3307 - mean_squared_error: 0.3307 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 0.3303 - mean_squared_error: 0.3303 - val_loss: 0.3571 - val_mean_squared_error: 0.3571\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3575 - val_mean_squared_error: 0.3575\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3300 - mean_squared_error: 0.3300 - val_loss: 0.3673 - val_mean_squared_error: 0.3673\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - val_loss: 0.3578 - val_mean_squared_error: 0.3578\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 294ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.3579 - val_mean_squared_error: 0.3579\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.3669 - val_mean_squared_error: 0.3669\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3296 - mean_squared_error: 0.3296 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.3665 - val_mean_squared_error: 0.3665\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3295 - mean_squared_error: 0.3295 - val_loss: 0.3576 - val_mean_squared_error: 0.3576\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.3662 - val_mean_squared_error: 0.3662\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3294 - mean_squared_error: 0.3294 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3293 - mean_squared_error: 0.3293 - val_loss: 0.3660 - val_mean_squared_error: 0.3660\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3291 - mean_squared_error: 0.3291 - val_loss: 0.3662 - val_mean_squared_error: 0.3662\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3288 - mean_squared_error: 0.3288 - val_loss: 0.3574 - val_mean_squared_error: 0.3574\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3664 - val_mean_squared_error: 0.3664\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3573 - val_mean_squared_error: 0.3573\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3287 - mean_squared_error: 0.3287 - val_loss: 0.3663 - val_mean_squared_error: 0.3663\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3285 - mean_squared_error: 0.3285 - val_loss: 0.3570 - val_mean_squared_error: 0.3570\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3281 - mean_squared_error: 0.3281 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.3562 - val_mean_squared_error: 0.3562\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3280 - mean_squared_error: 0.3280 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.3564 - val_mean_squared_error: 0.3564\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3278 - mean_squared_error: 0.3278 - val_loss: 0.3661 - val_mean_squared_error: 0.3661\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.3558 - val_mean_squared_error: 0.3558\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 0.3275 - mean_squared_error: 0.3275 - val_loss: 0.3659 - val_mean_squared_error: 0.3659\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3272 - mean_squared_error: 0.3272 - val_loss: 0.3552 - val_mean_squared_error: 0.3552\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.3665 - val_mean_squared_error: 0.3665\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3272 - mean_squared_error: 0.3272 - val_loss: 0.3550 - val_mean_squared_error: 0.3550\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3270 - mean_squared_error: 0.3270 - val_loss: 0.3660 - val_mean_squared_error: 0.3660\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3266 - mean_squared_error: 0.3266 - val_loss: 0.3545 - val_mean_squared_error: 0.3545\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3263 - mean_squared_error: 0.3263 - val_loss: 0.3666 - val_mean_squared_error: 0.3666\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.3541 - val_mean_squared_error: 0.3541\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3264 - mean_squared_error: 0.3264 - val_loss: 0.3670 - val_mean_squared_error: 0.3670\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3262 - mean_squared_error: 0.3262 - val_loss: 0.3539 - val_mean_squared_error: 0.3539\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3261 - mean_squared_error: 0.3261 - val_loss: 0.3668 - val_mean_squared_error: 0.3668\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.3538 - val_mean_squared_error: 0.3538\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.3255 - mean_squared_error: 0.3255 - val_loss: 0.3670 - val_mean_squared_error: 0.3670\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3254 - mean_squared_error: 0.3254 - val_loss: 0.3530 - val_mean_squared_error: 0.3530\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.3253 - mean_squared_error: 0.3253 - val_loss: 0.3671 - val_mean_squared_error: 0.3671\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3251 - mean_squared_error: 0.3251 - val_loss: 0.3528 - val_mean_squared_error: 0.3528\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3248 - mean_squared_error: 0.3248 - val_loss: 0.3679 - val_mean_squared_error: 0.3679\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3245 - mean_squared_error: 0.3245 - val_loss: 0.3529 - val_mean_squared_error: 0.3529\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.3246 - mean_squared_error: 0.3246 - val_loss: 0.3681 - val_mean_squared_error: 0.3681\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3244 - mean_squared_error: 0.3244 - val_loss: 0.3525 - val_mean_squared_error: 0.3525\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.3685 - val_mean_squared_error: 0.3685\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.3523 - val_mean_squared_error: 0.3523\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.3683 - val_mean_squared_error: 0.3683\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.3517 - val_mean_squared_error: 0.3517\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3240 - mean_squared_error: 0.3240 - val_loss: 0.3684 - val_mean_squared_error: 0.3684\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.3238 - mean_squared_error: 0.3238 - val_loss: 0.3516 - val_mean_squared_error: 0.3516\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.3233 - mean_squared_error: 0.3233 - val_loss: 0.3686 - val_mean_squared_error: 0.3686\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.3235 - mean_squared_error: 0.3235 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3232 - mean_squared_error: 0.3232 - val_loss: 0.3689 - val_mean_squared_error: 0.3689\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3230 - mean_squared_error: 0.3230 - val_loss: 0.3514 - val_mean_squared_error: 0.3514\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.3231 - mean_squared_error: 0.3231 - val_loss: 0.3688 - val_mean_squared_error: 0.3688\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.3511 - val_mean_squared_error: 0.3511\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3228 - mean_squared_error: 0.3228 - val_loss: 0.3687 - val_mean_squared_error: 0.3687\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3229 - mean_squared_error: 0.3229 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 0.3223 - mean_squared_error: 0.3223 - val_loss: 0.3693 - val_mean_squared_error: 0.3693\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3229 - mean_squared_error: 0.3229 - val_loss: 0.3509 - val_mean_squared_error: 0.3509\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3224 - mean_squared_error: 0.3224 - val_loss: 0.3690 - val_mean_squared_error: 0.3690\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3694 - val_mean_squared_error: 0.3694\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3220 - mean_squared_error: 0.3220 - val_loss: 0.3504 - val_mean_squared_error: 0.3504\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3216 - mean_squared_error: 0.3216 - val_loss: 0.3696 - val_mean_squared_error: 0.3696\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3215 - mean_squared_error: 0.3215 - val_loss: 0.3506 - val_mean_squared_error: 0.3506\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3218 - mean_squared_error: 0.3218 - val_loss: 0.3697 - val_mean_squared_error: 0.3697\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3219 - mean_squared_error: 0.3219 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.3700 - val_mean_squared_error: 0.3700\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3213 - mean_squared_error: 0.3213 - val_loss: 0.3503 - val_mean_squared_error: 0.3503\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 0.3211 - mean_squared_error: 0.3211 - val_loss: 0.3704 - val_mean_squared_error: 0.3704\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3208 - mean_squared_error: 0.3208 - val_loss: 0.3502 - val_mean_squared_error: 0.3502\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 0.3214 - mean_squared_error: 0.3214 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.3501 - val_mean_squared_error: 0.3501\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.3703 - val_mean_squared_error: 0.3703\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 0.3206 - mean_squared_error: 0.3206 - val_loss: 0.3499 - val_mean_squared_error: 0.3499\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3199 - mean_squared_error: 0.3199 - val_loss: 0.3705 - val_mean_squared_error: 0.3705\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.3204 - mean_squared_error: 0.3204 - val_loss: 0.3498 - val_mean_squared_error: 0.3498\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 323ms/step - loss: 0.3202 - mean_squared_error: 0.3202 - val_loss: 0.3706 - val_mean_squared_error: 0.3706\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.3497 - val_mean_squared_error: 0.3497\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.3496 - val_mean_squared_error: 0.3496\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 0.3203 - mean_squared_error: 0.3203 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.3196 - mean_squared_error: 0.3196 - val_loss: 0.3495 - val_mean_squared_error: 0.3495\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.3707 - val_mean_squared_error: 0.3707\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 0.3199 - mean_squared_error: 0.3199 - val_loss: 0.3493 - val_mean_squared_error: 0.3493\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 0.3201 - mean_squared_error: 0.3201 - val_loss: 0.3708 - val_mean_squared_error: 0.3708\n"
     ]
    }
   ],
   "source": [
    "history = aro_model.fit(\n",
    "    f_features_norm,\n",
    "    aro_y,\n",
    "    epochs=100,\n",
    "    batch_size=1213,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
